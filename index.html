
<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Michalis Vrigkas</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
        <meta name="description" content="Michalis Vrigkas' personal website" />
        <meta name="keywords" content="Computer Vision, Image Processing, Image Analysis, Machine Learning, Pattern Recognition, Medical Image Analysis, Biometrics, Cardiovascular Informatics" />

        <link rel="canonical" href="http://www.cs.uoi.gr/~mvrigkas">

        <!--[if lt IE 9]>
    <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

        <!--CSS styles-->
        <link rel="stylesheet" href="assets/css/bootstrap.css">
        <link rel="stylesheet" href="assets/css/font-awesome.min.css">
        <link rel="stylesheet" href="assets/css/perfect-scrollbar-0.4.5.min.css">
        <link rel="stylesheet" href="assets/css/magnific-popup.css">
        <link rel="stylesheet" href="assets/css/style.css">
    		<link rel="stylesheet" href="assets/css/publications.css" />
        <link id="theme-style" rel="stylesheet" href="assets/css/styles/myblue.css">

        <!--/CSS styles-->

        <!--Javascript files-->
        <script type="text/javascript" src="assets/js/jquery-1.10.2.js"></script>
        <script type="text/javascript" src="assets/js/TweenMax.min.js"></script>
        <script type="text/javascript" src="assets/js/jquery.touchSwipe.min.js"></script>
        <script type="text/javascript" src="assets/js/jquery.carouFredSel-6.2.1-packed.js"></script>
        <script type="text/javascript" src="assets/js/modernizr.custom.63321.js"></script>
        <script type="text/javascript" src="assets/js/jquery.dropdownit.js"></script>
        <script type="text/javascript" src="assets/js/jquery.stellar.min.js"></script>
        <script type="text/javascript" src="assets/js/ScrollToPlugin.min.js"></script>
        <script type="text/javascript" src="assets/js/bootstrap.min.js"></script>
        <script type="text/javascript" src="assets/js/jquery.mixitup.min.js"></script>
        <script type="text/javascript" src="assets/js/masonry.min.js"></script>
        <script type="text/javascript" src="assets/js/perfect-scrollbar-0.4.5.with-mousewheel.min.js"></script>
        <script type="text/javascript" src="assets/js/magnific-popup.js"></script>
        <script type="text/javascript" src="assets/js/custom.js"></script>
   		  <script type="text/javascript" src="assets/js/hidebib.js"></script>
        <!--/Javascript files-->

    </head>
    <body>
        <div id="wrapper">
            <a href="#sidebar" class="mobilemenu"><i class="icon-reorder"></i></a>

            <div id="sidebar">
                <div id="main-nav">
                    <div id="nav-container">
                        <div id="profile" class="clearfix">
                          <div class="title">
                            <h2>Michalis Vrigkas</h2>
                          </div>
                            <div class="portrate hidden-xs"></div>
                            <div class="title">

                                <h3>Assistant Professor</h3>
                                <h4>m v r i g k a s /at\ u o w m \dot\ g r</h4>
                                <h4>(properly processed)</h4>
                            </div>
                        </div>
                        <ul id="navigation">
                            <li>
                              <a href="#biography">
                                <div class="icon icon-home"></div>
                                <div class="text">About Me</div>
                              </a>
                            </li>

                            <li>
                              <a href="#teaching">
                                <div class="icon icon-book"></div>
                                <div class="text">Teaching</div>
                              </a>
                            </li>

                            <li>
                              <a href="#publications">
                                <div class="icon icon-edit"></div>
                                <div class="text">Publications</div>
                              </a>
                            </li>

                            <li>
                              <a href="#research">
                                <div class="icon icon-pencil"></div>
                                <div class="text">Research</div>
                              </a>
                            </li>

                            <!--<li>
                              <a href="#people">
                                <div class="icon icon-pencil"></div>
                                <div class="text">People</div>
                              </a>
                            </li>-->

                            <li>
                              <a href="#download">
                                <div class="icon icon-download-alt"></div>
                                <div class="text">Downloads</div>
                              </a>
                            </li>

                            <li>
                              <a href="#contact">
                                  <div class="icon icon-envelope"></div>
                                  <div class="text">Contact Me</div>
                              </a>
                            </li>

                        </ul>
                    </div>
                </div>

                <div class="social-icons">
                    <ul>
				                <li><a href="https://scholar.google.com/citations?user=hixpxHsAAAAJ&hl=en" target="_blank" class="ai ai-google-scholar" title="Google Scholar"></a></li>
                        <li><a href="https://www.scopus.com/authid/detail.uri?authorId=47062106300" target="_blank" class="ai ai-scopus-square" title="Scopus"></a></li>
                        <li><a href="http://www.researchgate.net/profile/Michalis_Vrigkas" target="_blank" class="ai ai-researchgate"title="ResearchGate"></a></li>
                        <li><a href="https://github.com/mvrigkas" target="_blank"><i class="icon-github" title="GitHub"></i></a></li>
                        <li><a href="https://www.linkedin.com/in/michalis-vrigkas-a3b09542" target="_blank"><i class="icon-linkedin" title="LinkedIn"></i></a></li>
                    </ul>
                </div>
            </div>

            <div id="main">

              <!--BIOGRAPHY-->
                <div id="biography" class="page home" data-pos="home">
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                <div class="row">
                                    <div class="clearfix visible-sm visible-xs"></div>
                                      <div class="col-sm-12 col-md-12">
                                          <h3 class="title">About me</h3>
                                          <div class="text row">
                                                <div class="col-md-3">
                                                    <img alt="image" src="images/UoWM-logo/uowm-logo_2.png" class="img-responsive">
                                                </div>
                                                <div class="col-md-12">
                                                  <p align="justify">I am an Assistant Professor at the <a href="http://www.uowm.gr/en/" target="_blank" title="University of Western Macedonia">University of Western Macedonia</a> at the <a href="https://cdm.uowm.gr/?lang=en" target="_blank" title="Department of Communication and Digital Media"> Department of Communication and Digital Media</a>, Kastoria, Greece. I received my Ph.D. from the <a href="http://www.cse.uoi.gr/en/" target="_blank" title="Department of Computer Science &amp; Engineering">Department of Computer Science &amp; Engineering</a>, <a href="http://www.uoi.gr/en/" target="_blank" title="University of Ioannina">University of Ioannina</a>, Greece, and my M.Sc. and B.Sc. in Computer Science from the same institution. For the Academic year 2018-2019, I was an Adjunct Lecturer at the <a href="http://www.cse.uoi.gr/en/" target="_blank" title="Department of Computer Science &amp; Engineering">Department of Computer Science &amp; Engineering</a>, <a href="http://www.uoi.gr/en/" target="_blank" title="University of Ioannina">University of Ioannina</a>.
                                                  In the past, I spent two years at the <a href="http://www.uh.edu" target="_blank" title="University of Houston">University of Houston</a>, TX, USA where I worked as a Postdoctoral Fellow at <a href="http://www.uh.edu/cbl" target="_blank" title="Computational Biomedicine Lab">Computational Biomedicine Lab</a> and at the <a href="https://www2.times.uh.edu/" target="_blank" title="TIMES">Texas Institute for Measurement, Evaluation & Statistics</a>.</p>
                                                  <p align="justify">My research covers a wide range of topics such as Virtual and Augmented Reality, Computer Vision, Image and Video Processing, Image Analysis, Machine Learning, and Pattern Recognition with applications also to Medical Image Analysis and Biometrics.</p>
                                              </div>
                                          </div>
                                      </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="pagecontents">
                        <div class="section color-1">
                            <div class="section-container">
                                <div class="row">

                                  <div class="col-md-5">
                                      <div class="title text-center">
                                          <h3>Academic Positions</h3>
                                      </div>
                                      <ul class="ul-dates">
                                          <li>
                                              <div class="dates">
                                                  <span>Present</span>
                                                  <span>2020</span>
                                              </div>
                                              <div class="content">
                                                <div class="description">
                                                    <img alt="image" src="images/UoWM-logo/uowm-logo_0.png" width="60em" height="auto" align="right" class="img-responsive">
                                                    <h4>Assistant Professor</h4>
                                                    <p><em>University of Western Macedonia</em>, Department of Communication and Digital Media</p>
                                                </div>
                                              </div>
                                          </li>
                                          <li>
                                              <div class="dates">
                                                  <span>2020</span>
                                                  <span>2019</span>
                                              </div>
                                              <div class="content">
                                                <div class="description">
				                                           <img alt="image" src="images/cs-logo/CSE-UOI-LOGO-EN.png" width="59em" height="auto" align="right" class="img-responsive">
                                                    <h4>Research Scientist</h4>
                                                    <p><em>University of Ioannina</em>, Department of Computer Science &amp; Engineering</p>
                                                </div>
                                              </div>
                                          </li>
                                          <li>
                                              <div class="dates">
                                                  <span>2019</span>
                                                  <span>2018</span>
                                              </div>
                                              <div class="content">
                                                <div class="description">
				                                           <img alt="image" src="images/cs-logo/CSE-UOI-LOGO-EN.png" width="59em" height="auto" align="right" class="img-responsive">
                                                    <h4>Adjunct Lecturer</h4>
                                                    <p><em>University of Ioannina</em>, Department of Computer Science &amp; Engineering</p>
                                                </div>
                                              </div>
                                          </li>
                                          <li>
                                              <div class="dates">
                                                  <span>2018</span>
                                                  <span>2016</span>
                                              </div>
                                              <div class="content">
                                                <div class="description">
				                                           <img alt="image" src="images/uh-logo/uh_logo.png" width="58em" height="auto" align="right" class="img-responsive">
                                                  <h4>Postdoctoral Fellow</h4>
                                                  <p><em>University of Houston</em>, Computational Biomedicine Lab</p>
                                                  </div>
                                              </div>
                                          </li>
                                      </ul>
                                  </div>

                                  <div class="col-md-5 col-md-offset-1">
                                      <div class="title text-center">
                                          <h3>Education</h3>
                                      </div>
                                      <ul class="ul-card">
                                          <li>
                                              <div class="dy">
                                                  <span class="degree">Ph.D.</span>
                                                  <span class="year">2016</span>
                                              </div>
                                              <div class="description">
							                                    <img alt="image" src="images/cs-logo/CSE-UOI-LOGO-EN.png" width="63em" height="auto" align="right" class="img-responsive">
                                                  <p class="what">Ph.D. in Computer Science</p>
                                                  <p class="where">University of Ioannina</p>
                                                  <p class="where">Department of Computer Science and Engineering</p>
                                              </div>
                                          </li>
                                          <li>
                                              <div class="dy">
                                                  <span class="degree">M.Sc.</span><span class="year">2010</span>
                                              </div>
                                              <div class="description">
						                                     <img alt="image" src="images/cs-logo/csuoilogo5.png" width="65em" height="auto" align="right" class="img-responsive">
                                                  <p class="what">Master in Computer Science</p>
                                                  <p class="where">University of Ioannina</p>
                                                  <p class="where">Department of Computer Science</p>
                                              </div>
                                          </li>
                                          <li>
                                              <div class="dy">
                                                  <span class="degree">B.Sc.</span><span class="year">2008</span>
                                              </div>
                                              <div class="description">
							                                    <img alt="image" src="images/cs-logo/csuoilogo5.png" width="65em" height="auto" align="right" class="img-responsive">
                                                  <p class="what">Bachelor in Computer Science</p>
                                                  <p class="where">University of Ioannina</p>
                                                  <p class="where">Department of Computer Science</p>
                                              </div>
                                          </li>
                                      </ul>
                                  </div>
                                </div>

                            <div class="row">
                                <div class="col-md-10 col-md-offset-1">

                                <div class="title text-center">
                                  <br>
                                    <h3>Honors and Awards </h3>
                                </div>
                                <ul class="timeline">

                                  <li class="open">
                                      <div class="date">January 2024</div>
                                      <div class="circle"></div>
                                      <div class="data">
                                          <div class="subject">Excellence in Research Award</div>
                                          <div class="text row">
                                              <div class="col-md-2">
                                                  <img alt="image" class="thumbnail img-responsive" src="images/UoWM-logo/uowm-logo_0.png" width="65em" height="auto" align="left">
                                              </div>
                                              <div class="col-md-10">
                                                2nd prize of excellence in research of the Faculty of Social Sciences and Humanities, University of Western Macedonia. For the research work entitled &ldquo;<em>Facemask: A new image dataset for the automated identification of people wearing masks in the wild</em>&rdquo; published in the International Journal: <em>Sensors</em>.
                                              </div>
                                          </div>
                                      </div>
                                  </li>

                                  <li>
                                      <div class="date">January 2023</div>
                                      <div class="circle"></div>
                                      <div class="data">
                                          <div class="subject">Excellence in Research Award</div>
                                          <div class="text row">
                                              <div class="col-md-2">
                                                  <img alt="image" class="thumbnail img-responsive" src="images/UoWM-logo/uowm-logo_0.png" width="65em" height="auto" align="left">
                                              </div>
                                              <div class="col-md-10">
                                                2nd prize of excellence in research of the Faculty of Social Sciences and Humanities, University of Western Macedonia. For the research work entitled &ldquo;<em>Human activity recognition using robust adaptive privileged probabilistic learning</em>&rdquo; published in the International Journal: <em>Pattern Analysis and Applications</em>.
                                              </div>
                                          </div>
                                      </div>
                                  </li>

                                  <li>
                                      <div class="date">July 2018</div>
                                      <div class="circle"></div>
                                      <div class="data">
                                          <div class="subject">NVIDIA GPU Grant</div>
                                          <div class="text row">
                                              <div class="col-md-2">
                                                  <img alt="image" class="thumbnail img-responsive" src="images/other-logos/nvidia-logo.png" width="65em" height="auto" align="left">
                                              </div>
                                              <div class="col-md-10">
                                                NVIDIA Corporation supports my research with the donation of one Titan Xp GPU.
                                              </div>
                                          </div>
                                      </div>
                                  </li>

                                    <li>
                                        <div class="date">March 2017</div>
                                        <div class="circle"></div>
                                        <div class="data">
                                            <div class="subject">Outstanding Reviewer</div>
                                            <div class="text row">
                                                <div class="col-md-2">
                                                    <img alt="image" class="thumbnail img-responsive" src="images/other-logos/elsevier.jpg" width="55em" height="auto" align="left">
                                                </div>
                                                <div class="col-md-10">
                                                  Outstanding reviewer for the sicentific Journal <em>Signal Processing: Image Communication</em>.
                                                </div>
                                            </div>
                                        </div>
                                    </li>
                                    <li>
                                        <div class="date">October 2016</div>
                                        <div class="circle"></div>
                                        <div class="data">
                                            <div class="subject">Outstanding Reviewer</div>
                                            <div class="text row">
                                              <div class="col-md-2">
                                                  <img alt="image" class="thumbnail img-responsive" src="images/other-logos/elsevier.jpg" width="55em" height="auto" align="left">
                                              </div>
                                              <div class="col-md-10">
                                                Outstanding reviewer for the sicentific Journal <em>Pervasive and Mobile Computing</em>.
                                              </div>
                                            </div>
                                        </div>
                                    </li>
                                    <li>
                                        <div class="date">June 2016</div>
                                        <div class="circle"></div>
                                        <div class="data">
                                            <div class="subject">Honorable Mention Paper Award</div>
                                            <div class="text row">
                                              <div class="col-md-2">
                                                  <img alt="image" class="thumbnail img-responsive" src="images/other-logos/icb2016_logo.png" width="105em" height="auto" align="left">
                                              </div>
                                              <div class="col-md-10">
                                                I was the recipient of the best paper award for the paper entitled <em>&ldquo;Exploiting privileged information for facial expression recognition&rdquo;</em>. One of two papers selected among 151 submitted and 52 accepted papers at <a href="http://icb2016.hh.se/Awards" class="tooltips" title="ICB2016" target="_blank">IAPR/IEEE International Conference on Biometrics (ICB)</a>.
                                              </div>
                                            </div>
                                        </div>
                                    </li>
                                    <li>
                                        <div class="date">2003</div>
                                        <div class="circle"></div>
                                        <div class="data">
                                            <div class="subject">Excellence Award</div>
                                            <div class="text row">
                                                <div class="col-md-2">
                                                    <img alt="image" class="thumbnail img-responsive" src="images/other-logos/minedu-logo.jpg" width="125em" height="auto" align="left">
                                                </div>
                                                <div class="col-md-10">
                                                   Excellence award from the Ministry of Education of Greece.
                                                </div>
                                            </div>
                                        </div>
                                    </li>
                                </ul>
                              </div>
                          </div>
                      </div>
                    </div>
                </div>
            </div>

            <!-- TEACHING -->
            <div id="teaching" class="page">
                <div class="pageheader">
                    <div class="headercontent">
                        <div class="section-container">
                            <h2 class="title">Courses</h2>
                              <div class="row">
                                <div class="col-md-12">
                                    <blockquote>Education is an admirable thing. But it is well to remember from time to time that nothing that is worth knowing can be taught.
                                      <footer>
                                        <cite>
                                          Oscar Wilde (1854 - 1900)
                                        </cite>
                                      </footer>
                                    </blockquote>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="pagecontents">
                    <div class="section color-1">
                        <div class="section-container">
                            <div class="row">
                                <div class="title text-center">
                                    <h3>Currrent Teaching</h3>
                                </div>

                                <ul class="ul-boxed list-unstyled">
                                  <li>
                                  <div class="content">
                                    <div class="text row">
                                      <div class="col-md-10">
                                          Below are the courses that I teach for the Academic year 2023-2024 at the <a href="http://www.cdm.uowm.gr" target="_blank" title="Department of Communication and Digital Media">Department of Communication and Digital Media</a> of the <a href="http://www.uowm.gr/" target="_blank" title="University of Western Macedonia">University of Western Macedonia</a>
                                      </div>
                                      <div class="col-md-2">
                                        <img alt="image" src="images/UoWM-logo/logo-cdm-en.png" width="130em" height="auto" align="right" class="img-responsive">
                                      </div>
                                    </div>
                                  </div>
                                </li>
                              </ul>

                              <div class="row">
                                <div class="col-md-12">
                                  <ul class="ul-boxed list-unstyled">
                                    <li><strong>Undergraduate Courses</strong></li>
                                  </ul>
                                </div>
                              </div>

                              <div class="row">
                                <div class="col-md-6">
                                <ul class="ul-dates">
                                  <li>
                                        <div class="dates">
                                            <span>Fall</span>
                                            <span>2023</span>
                                        </div>
                                        <div class="content">
                                          <div class="text row">
                                            <div class="col-md-12">
                                              CDM3114: Graphics Design and Visual Communication
                                              <p><span class="label label-danger">Instructor</span>&nbsp;&nbsp;<em>For more information see the course web page <a href="https://eclass.uowm.gr/courses/CDM118/" title="Graphic Design and Visual Communication">here</a>.</em></p>
                                            </div>
                                          </div>
                                        </div>
                                    </li>

                                    <li>
                                      <div class="dates">
                                          <span>Fall</span>
                                          <span>2023</span>
                                      </div>
                                      <div class="content">
                                        <div class="text row">
                                          <div class="col-md-12">
                                            CMD5134: Interactive Multimedia
                                            <p><span class="label label-danger">Instructor</span>&nbsp;&nbsp;<em>For more information see the course web page <a href="https://eclass.uowm.gr/courses/CDM160/" title="Interactive Multimedia">here</a>.</em></p>
                                          </div>
                                        </div>
                                      </div>
                                  </li>

                                  <li>
                                    <div class="dates">
                                        <span>Fall</span>
                                        <span>2023</span>
                                    </div>
                                    <div class="content">
                                      <div class="text row">
                                        <div class="col-md-12">
                                          CDM5295: Theory and Design of 3D Graphics for Virtual Enviroments
                                          <p><span class="label label-danger">Instructor</span>&nbsp;&nbsp;<em>For more information see the course web page <a href="https://eclass.uowm.gr/courses/CDM161/" title="Theory and Design of 3D Graphics for Virtual Enviroments">here</a>.</em></p>
                                        </div>
                                      </div>
                                    </div>
                                </li>

                              </ul>
                            </div>

                              <div class="col-md-6 ">
                              <ul class="ul-dates">
                                <!--<li>
                                      <div class="dates">
                                          <span>Spring</span>
                                          <span>2024</span>
                                      </div>
                                      <div class="content">
                                        <div class="text row">
                                          <div class="col-md-12">
                                            CDM4255: Mobile Digital Media and Diffusible Computation
                                            <p><span class="label label-danger">Instructor</span>&nbsp;&nbsp;<em>For more information see the course web page <a href="https://eclass.uowm.gr/courses/CDM138/" title="Mobile Digital Media and Diffusible Computation">here</a>.</em></p>
                                          </div>
                                        </div>
                                      </div>
                                  </li>-->

                                  <li>
                                      <div class="dates">
                                          <span>Spring</span>
                                          <span>2024</span>
                                      </div>
                                      <div class="content">
                                        <div class="text row">
                                          <div class="col-md-12">
                                          CDM6115: Theory and Design of Animation
                                          <p><span class="label label-danger">Instructor</span>&nbsp;&nbsp;<em>For more information see the course web page <a href="https://eclass.uowm.gr/courses/CDM162/" title="Theory and Design of Animation">here</a>.</em></p>
                                          </div>
                                        </div>
                                      </div>
                                  </li>

                                  <li>
                                      <div class="dates">
                                          <span>Spring</span>
                                          <span>2024</span>
                                      </div>
                                      <div class="content">
                                        <div class="text row">
                                          <div class="col-md-12">
                                          CDM8245: Theory and Design of Virtual and Augmented Reality Applications
                                          <p><span class="label label-danger">Instructor</span>&nbsp;&nbsp;<em>For more information see the course web page <a href="https://eclass.uowm.gr/" title="Theory and Design of Virtual and Augmented Reality Applications">here</a>.</em></p>
                                          </div>
                                        </div>
                                      </div>
                                  </li>

                                </ul>

                              </div>
                            </div>

                            <br>

                              <div class="row">
                                <div class="col-md-12">
                                  <ul class="ul-boxed list-unstyled">
                                    <li><strong>Graduate Courses</strong></li>

                                    <li>
                                    <div class="content">
                                      <div class="text row">
                                        <div class="col-md-11">
                                            Postgraduate Program (M.Sc.) in &ldquo;<a href="https://gamedev.uowm.gr/" target="_blank">Gaming and Multimedia Application Development</a>&rdquo; organized by the Department of Communication and Digital Media of the University of Western Macedonia.
                                        </div>
                                        <div class="col-md-1">
                                          <img alt="image" src="images/UoWM-logo/logogamingmsc.png" width="50em" height="auto" align="right" class="img-responsive">
                                        </div>
                                      </div>
                                    </div>
                                  </li>

                                </ul>
                              </div>


                          <div class="col-md-6">
                            <ul class="ul-dates">
                              <li>
                                  <div class="dates">
                                      <span>Fall</span>
                                      <span>2023</span>
                                  </div>
                                  <div class="content">
                                    <div class="text row">
                                      <div class="col-md-12">
                                        Digital Multimedia Processing
                                        <p><span class="label label-danger">Instructor - Co-teaching</span>&nbsp;&nbsp;<em>For more information see the course web page <a href="https://eclass.uowm.gr/courses/GDEV104/" title="Digital Multimedia Processing">here</a>.</em></p>
                                      </div>
                                    </div>
                                  </div>
                              </li>
                            </ul>
                          </div>

                          <div class="col-md-6">
                            <ul class="ul-dates">
                                <li>
                                    <div class="dates">
                                        <span>Spring</span>
                                        <span>2024</span>
                                    </div>
                                    <div class="content">
                                      <div class="text row">
                                        <div class="col-md-12">
                                          Augmented and Virtual Reality
                                          <p><span class="label label-danger">Instructor - Co-teaching</span>&nbsp;&nbsp;<em>For more information see the course web page <a href="https://eclass.uowm.gr/" title="Augmented and Virtual Reality">here</a>.</em></p>
                                        </div>
                                      </div>
                                    </div>
                                </li>
                            </ul>
                          </div>

                        </div>
                            <br>

                            <div class="row">
                              <div class="col-md-12">
                                <ul class="ul-boxed list-unstyled">
                                    <li>
                                    <div class="content">
                                      <div class="text row">
                                        <div class="col-md-11">
                                            Interdepartmental Postgraduate Program (M.Sc.) in &ldquo;<a href="https://teachedumsc.uowm.gr/" target="_blank">Education Sciences: Teacher Training in Innovative Approaches to Teaching and Learning</a>&rdquo; organized by the Department of Primary Education in collaboration with the Department of Communication and Digital Media and the Department of Psychology of the School of Social Sciences and Humanities of the University of Western Macedonia.
                                        </div>
                                        <div class="col-md-1">
                                          <img alt="image" src="images/UoWM-logo/TEACHEDUMSC-logo.png" width="50em" height="auto" align="right" class="img-responsive">
                                        </div>
                                      </div>
                                    </div>
                                  </li>

                                  </ul>
                                </div>
                              </div>

                              <ul class="ul-dates">
                                <li>
                                    <div class="dates">
                                        <span>Fall</span>
                                        <span>2023</span>
                                    </div>
                                    <div class="content">
                                      <div class="text row">
                                        <div class="col-md-12">
                                          Didactic Utilization of ICT in Education
                                          <p><span class="label label-danger">Instructor - Co-teaching</span>&nbsp;&nbsp;<em>For more information see the course web page <a href="https://eclass.uowm.gr/courses/TTIATL104/" title="Didactic Utilization of ICT in Education">here</a>.</em></p>
                                        </div>
                                      </div>
                                    </div>
                                </li>
                              </ul>

                          </div>
                      </div>
                  </div>
              </div>

              <div class="pagecontents">
                  <div class="section color-2">
                      <div class="section-container">
                          <div class="row">
                              <div class="title text-center">
                                  <h3>Teaching History</h3>
                              </div>

                              <ul class="ul-boxed list-unstyled">
                                <li>
                                <div class="content">
                                  <div class="text row">
                                    <div class="col-md-10">
                                        Below is a list of courses that I have taught at the <a href="http://www.cdm.uowm.gr" target="_blank" title="Department of Communication and Digital Media">Department of Communication and Digital Media</a> of the <a href="http://www.uowm.gr/" target="_blank" title="University of Western Macedonia">University of Western Macedonia</a>
                                    </div>
                                    <div class="col-md-2">
                                      <img alt="image" src="images/UoWM-logo/logo-cdm-en.png" width="130em" height="auto" align="right" class="img-responsive">
                                    </div>
                                  </div>
                                </div>
                              </li>
                            </ul>

                          <ul class="ul-dates-gray">
                            <li>
                                <div class="dates">
                                    <span>2023</span>
                                    <span>2020</span>
                                </div>
                                <div class="content">
                                      CDM4255: Mobile Digital Media and Diffusible Computation
                                      <p><span class="label label-danger">Instructor</span></p>
                                </div>
                            </li>

                            <li>
                                <div class="dates">
                                    <span>2021</span>
                                    <span>2020</span>
                                </div>
                                <div class="content">
                                      CDM4145: Creative Studio and Audiovisual Productions
                                      <p><span class="label label-danger">Instructor</span></p>
                                </div>
                            </li>
                            <li>
                              <div class="dates">
                                  <span>2021</span>
                                  <span>2020</span>
                              </div>
                              <div class="content">
                                  DMC563: 3D Digital Applications
                                  <p><span class="label label-danger">Instructor</span></p>
                              </div>
                          </li>
                          <li>
                              <div class="dates">
                                  <span>2021</span>
                                  <span>2020</span>
                              </div>
                              <div class="content">
                                  DMC638: Interactive Communication
                                  <p><span class="label label-danger">Instructor</span></p>
                              </div>
                          </li>

                          <li>
                            <div class="dates">
                                <span>2022</span>
                                <span>2020</span>
                            </div>
                            <div class="content">
                                DMC737: Integrated Multimedia Creation
                                <p><span class="label label-danger">Instructor</span></p>
                            </div>
                          </li>

                              <div class="dates">
                                  <span>2020</span>
                                  <span>2019</span>
                              </div>
                              <div class="content">
                                DMC425: Creative Animation
                                  <p><span class="label label-danger">Instructor</span></p>
                              </div>
                          </li>
                          <li>
                              <div class="dates">
                                  <span>2020</span>
                                  <span>2019</span>
                              </div>
                              <div class="content">
                                  DMC628: Public Relations and Marketing on the Internet
                                  <p><span class="label label-danger">Instructor - Co-teaching</span></p>
                              </div>
                          </li>
                      </ul>

                          <br>
                          <ul class="ul-boxed list-unstyled">
                            <li>
                            <div class="content">
                              <div class="text row">
                                <div class="col-md-11">
                                    Below are the courses that I have taught for the Academic year 2018-2019 at the <a href="http://www.cse.uoi.gr/en/" target="_blank" title="Department of Computer Science &amp; Engineering">Department of Computer Science &amp; Engineering</a> of the <a href="http://www.uoi.gr/en/" target="_blank" title="University of Ioannina">University of Ioannina</a>
                                </div>
                                <div class="col-md-1">
                                  <img alt="image" src="images/cs-logo/CSE-UOI-LOGO-EN.png" width="50em" height="auto" align="right" class="img-responsive">
                                </div>
                              </div>
                            </div>
                          </li>
                          </ul>

                          <ul class="ul-dates-gray">
                              <li>
                                  <div class="dates">
                                      <span>2019</span>
                                      <span>2018</span>
                                  </div>
                                  <div class="content">
                                      <h4>Object Oriented Programming Techniques</h4>
                                      <p><span class="label label-danger">Instructor</span></p>
                                  </div>
                              </li>
                              <li>
                                  <div class="dates">
                                      <span>2019</span>
                                      <span>2018</span>
                                  </div>
                                  <div class="content">
                                      <h4>Digital Image Processing</h4>
                                      <p><span class="label label-danger">Instructor</span></p>
                                  </div>
                              </li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>

                <!--PUBLICATIONS-->
                <div id="publications" class="page">
                    <div class="page-container">
                        <div class="pageheader">
                            <div class="headercontent">
                                <div class="section-container">
                                    <h2 class="title">Publications</h2>
                                    <div class="col-md-12">
                                        <div class="row" align="justify">
                                            <p style="color:grey;"><em><small>&copy; <strong>Copyright Notice</strong>: This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author's copyright. These works may not be reposted without the explicit permission of the copyright holder. All persons copying this information are expected to adhere to the terms and constraints invoked by each author's copyright and/or copyright holders. All statements of fact, opinion or conclusions contained herein are those of the authors and should not be construed as representing the official views or policies of the sponsors. In most cases, these works may not be reposted without the explicit permission of the copyright holders. Please contact authors for further details.</small></em></p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="pagecontents">
                            <div class="section color-1" id="filters">
                                <div class="section-container">
                                    <div class="row">
                                        <div class="col-md-3">
                                            <h3>Filter by type:</h3>
                                        </div>
                                        <div class="col-md-6">
                                            <select id="cd-dropdown" name="cd-dropdown" class="cd-select">
                                                <option class="filter" value="all" selected>All types</option>
                                                <option class="filter" value="jpaper">Jounal Papers</option>
                                                <option class="filter" value="cpaper">Conference Papers</option>
                                                <option class="filter" value="cabstract">Conference Papers - Abstracts</option>
                                                <option class="filter" value="book">Books - Edited Books</option>
                                                <option class="filter" value="thesis">Theses</option>
                                                <!-- <option class="filter" value="bookchapter">Book Chapters</option>
                                                <option class="filter" value="book">Books</option>
                                                <option class="filter" value="report">Reports</option>
                                                <option class="filter" value="tpaper">Technical Papers</option> -->
                                            </select>
                                        </div>
                                        <div class="col-md-3">
                                            <select id="cd-dropdown" name="cd-dropdown" class="cd-select">
                                                <option class="filter" value="all" selected>All years</option>
                                                <option class="filter" value="2024">2024</option>
                                                <option class="filter" value="2023">2023</option>
                                                <option class="filter" value="2022">2022</option>
                                                <option class="filter" value="2021">2021</option>
                                                <option class="filter" value="2020">2020</option>
                                                <option class="filter" value="2019">2019</option>
                                                <option class="filter" value="2018">2018</option>
                                                <option class="filter" value="2017">2017</option>
                                                <option class="filter" value="2016">2016</option>
                                                <option class="filter" value="2015">2015</option>
                                                <option class="filter" value="2014">2014</option>
                                                <option class="filter" value="2013">2013</option>
                                                <option class="filter" value="2012">2012</option>
                                                <option class="filter" value="2011">2011</option>
                                            </select>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="section color-2" id="pub-grid">
                                <div class="section-container">

                                    <div class="row">
                                        <div class="col-md-12">
                                            <div class="pitems">

                                              <!--ISBI 2024-->
                                               <div class="item mix cpaper 2024" data-year="2024">
                                                   <div class="pubmain">
                                                       <div class="pubassets">
                                                           <a href="#" class="tooltips" title="External link" target="_blank">
                                                               <i class="icon-external-link"></i>
                                                           </a>
                                                           <a href="publications/Conferences/C21_ISBI_2024_Athens.pdf" class="tooltips" title="Download" target="_blank">
                                                               <i class="icon-file-text-alt"></i>
                                                           </a>
                                                       </div>
                                                       <span id="publications-list">
                                                         <ul class"list-unstyled-left">
                                                           <li>
                                                              <div class="publication-inpress">2024 <br>(To appear)</div>
      			                                                  <!--<div class="publication-year">2024</div>-->
                                                              <h4 class="pubtitle">Accurate cell segmentation based on generative adversarial networks and nuclei guide factors</h4>
                                                              <div class="pubauthor">K. Lavntaniti, M.E. Plissiti, <strong>M. Vrigkas</strong>, C. Nikou</div>
                                                              <div class="pubcite"><span class="label label-danger">Conference Paper</span> Proc. 21st IEEE International Symposium on Biomedical Imaging (ISBI), Athens Greece, May 27-30, 2024</div>
                                                   </div>
                                                   <div class="pubdetails">
                                                       <h4>Abstract</h4>
                                                       <div class="span-boxcolor">
                                                       <p align="justify">
                                                         The accurate segmentation of cells in cervical images is crucial for the recognition of pathological situations and the estimation of their severity. In this work, we investigate the segmentation of both the nucleus and the cytoplasm of each cell based on two Generative Adversarial Networks (GANs). First, we detect the location of the nucleus with the extraction of the nucleus boundaries in each cell, which is obtained by the training of the Nucleus-GAN. The segmented nucleus area serves as a guide factor for the definition of the cell boundary, and it is used as input in the Cell-GAN, for the segmentation of the cell boundaries. As it is verified by the experimental results, the proposed method is efficient and leads to accurate nucleus and cell boundaries, presenting high performance.
                                                       </p>
                                                       </div>
                                                       <br>
                                                       <h4>BibTex</h4>
                                                       <pre xml:space="preserve">
@inproceedings{Lavntaniti_etal_ISBI2024,
author    = {Kostantsa Lavntaniti and Marina E. Plissiti and Michalis Vrigkas and Christophoros Nikou},
title     = {Accurate cell segmentation based on generative adversarial networks and nuclei guide factors},
booktitle = {Proc. 21st IEEE International Symposium on Biomedical Imaging (ISBI)},
address   = {Athens, Greese},
pages     = {},
month     = {May},
year      = {2024}
}</pre>
                                                           </li>
                                                         </ul>
                                                       </div>
                                                   </span>
                                               </div>

                                               <!--MDPI EDITED BOOK 2024-->
                                                <div class="item mix book 2024" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.mdpi.com/books/reprint/8619-advances-in-biomedical-image-processing-and-analysis" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                        </div>
                                                        <span id="publications-list">
                                                          <ul class"list-unstyled-left">
                                                            <li>
                                                               <div class="publication-year">2024</div>
                                                               <h4 class="pubtitle">Advances in Biomedical Image Processing and Analysis</h4>
                                                               <div class="pubauthor"><strong>M. Vrigkas</strong>, C. Nikou, I.A. Kakadiaris (Eds.)</div>
                                                               <div class="pubcite"><span class="label label-primary">Edited Book</span> Applied Sciences, ISBN 978-3-0365-9639-6, doi: 10.3390/books978-3-0365-9639-6, January 2024</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Summary</h4>
                                                        <div class="span-boxcolor">
                                                        <p align="justify">
                                                          Rapid growth in algorithms and computing power over recent years has spurred the emergence of machine learning and image processing techniques as new tools, which are rapidly entering every aspect of our life, from intelligent personal assistance such as Siri, Alexa, and Google Home to self-driving cars. The medical community has begun taking advantage of these new possibilities to create new predictive models and improve existing models. For example, novel methods applying machine learning and image processing/analysis methods that are robust and theoretically sound to solve the learning task efficiently and intuitively have become widespread across different facets of biomedical imaging for identifying complex patterns. Likewise, advances in biomedical imaging may lead to new technologies for developing predictive models for all diseases and guide the decision of who should receive preventive therapy.
                                                        </p>
                                                        </div>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                    </span>
                                                </div>

                                              <!--Computers 2023-->
                                              <div class="item mix jpaper 2023" data-year="2023">
                                                  <div class="pubmain">
                                                      <div class="pubassets">
                                                          <a href="https://www.mdpi.com/2073-431X/12/11/227" class="tooltips" title="External link" target="_blank">
                                                              <i class="icon-external-link"></i>
                                                          </a>
                                                          <a href="publications/Journals/J13_Computers_2023.pdf" class="tooltips" title="Download" target="_blank">
                                                              <i class="icon-file-text-alt"></i>
                                                          </a>
                                                      </div>
                                                      <span id="publications-list">
                                                        <ul class"list-unstyled-left">
                                                          <li>
                                                           <div class="publication-year">2023</div>
                                                      <h4 class="pubtitle">Creating location-based augmented reality games and immersive experiences for touristic destination marketing and education</h4>
                                                      <div class="pubauthor">A. Kleftodimos, A. Evagelou, S. Gkoutzios, M. Matsiola, <strong>M. Vrigkas</strong>, A. Yannacopoulou, A. Triantafillidou, G. Lappas</div>
                                                      <div class="pubcite"><span class="label label-success">Journal Paper</span>Computers, vol. 12, no. 11, pp. 1-34, article number 227, November 2023.</div>
                                                  </div>
                                                  <div class="pubdetails">
                                                      <h4>Abstract</h4>
                                                      <div class="span-boxcolor">
                                                      <p align="justify">
                                                        The aim of this paper is to present an approach that utilizes several mixed reality technologies for touristic promotion and education. More specifically, mixed reality applications and games were created to promote the mountainous areas of Western Macedonia, Greece, and to educate visitors on various aspects of these destinations, such as their history and cultural heritage. Location-based augmented reality (AR) games were designed to guide the users to visit and explore the destinations, get informed, gather points and prizes by accomplishing specific tasks, and meet virtual characters that tell stories. Furthermore, an immersive lab was established to inform visitors about the region of interest through mixed reality content designed for entertainment and education. The lab visitors can experience content and games through virtual reality (VR) and augmented reality (AR) wearable devices. Likewise, 3D content can be viewed through special stereoscopic monitors. An evaluation of the lab experience was performed with a sample of 82 visitors who positively evaluated features of the immersive experience such as the level of satisfaction, immersion, educational usefulness, the intention to visit the mountainous destinations of Western Macedonia, intention to revisit the lab, and intention to recommend the experience to others.
                                                      </p>
                                                      </div>
                                                      <br>
                                                      <h4>BibTex</h4>
                                                      <pre xml:space="preserve">
@article{Computers_23,
author         = {Alexandros Kleftodimos and Athanasios Evagelou and Stefanos Gkoutzios and Maria Matsiola and Michalis Vrigkas and Anastasia Yannacopoulou and Amalia Triantafillidou and Georgios Lappas},
title          = {Creating location-based augmented reality games and immersive experiences for touristic destination marketing and education},
journal        = {Computers},
volume         = {12},
number         = {11},
pages          = {1--34},
article-number = {227},
month          = {November},
year           = {2023},
doi            = {10.3390/computers12110227}
}</pre>
                                                          </li>
                                                        </ul>
                                                      </div>
                                                  </span>
                                              </div>

                                              <!--3DCVP_ICIP 2023-->
                                               <div class="item mix cpaper 2023" data-year="2023">
                                                   <div class="pubmain">
                                                       <div class="pubassets">
                                                           <a href="https://ieeexplore.ieee.org/document/10328382" class="tooltips" title="External link" target="_blank">
                                                               <i class="icon-external-link"></i>
                                                           </a>
                                                           <a href="publications/Conferences/C20_3DCVPICIP_2023_Malaisia.pdf" class="tooltips" title="Download" target="_blank">
                                                               <i class="icon-file-text-alt"></i>
                                                           </a>
                                                       </div>
                                                       <span id="publications-list">
                                                         <ul class"list-unstyled-left">
                                                           <li>
                                                             <!--<div class="publication-inpress">2023 <br>(To appear)</div>-->
      			                                                  <div class="publication-year">2023</div>
                                                              <h4 class="pubtitle">A virtual reality 3D game: A comparison between an immersive virtual reality application and a desktop experience</h4>
                                                              <div class="pubauthor"><strong>M. Vrigkas</strong>, C. Nikou</div>
                                                              <div class="pubcite"><span class="label label-danger">Conference Paper</span> Proc. IEEE International Conference on Image Processing Challenges and Workshops (ICIPCW), pp. 3725-3729, Kuala Lumpur, Malaysia, October 8-11, 2023</div>
                                                   </div>
                                                   <div class="pubdetails">
                                                       <h4>Abstract</h4>
                                                       <div class="span-boxcolor">
                                                       <p align="justify">
                                                         The work aims to design and implement a 3D interactive and addictive object avoidance game using the Unity platform. The implementation of the immersive virtual reality application uses any smart mobile device as an input and output device, utilizing its accelerometer and compass to record the orientation and rotation data of the device in 3D space and capture the digital environment stereoscopically on the device screen. A comparative study between a virtual reality and a desktop real-time 3D game is performed to analyze the various attributes of the game and determine which medium is most effective.
                                                       </p>
                                                       </div>
                                                       <br>
                                                       <h4>BibTex</h4>
                                                       <pre xml:space="preserve">
@inproceedings{Vrigkas_et_al_3DCVP_ICIP23,
author    = {Michalis Vrigkas and Christophoros Nikou},
title     = {A virtual reality 3D game: A comparison between an immersive virtual reality application and a desktop experience},
booktitle = {Proc. IEEE International Conference on Image Processing Challenges and Workshops (ICIPCW)},
address   = {Kuala Lumpur, Malaysia},
pages     = {3725--3729},
month     = {October},
year      = {2023},
doi       = {doi: 10.1109/ICIPC59416.2023.10328382}
}</pre>
                                                           </li>
                                                         </ul>
                                                       </div>
                                                   </span>
                                               </div>

                                              <!--ICIAP 2023-->
                                               <div class="item mix cpaper 2023" data-year="2023">
                                                   <div class="pubmain">
                                                       <div class="pubassets">
                                                           <a href="https://link.springer.com/chapter/10.1007/978-3-031-43148-7_34" class="tooltips" title="External link" target="_blank">
                                                               <i class="icon-external-link"></i>
                                                           </a>
                                                           <a href="publications/Conferences/C19_ICIAP_2023_Udine.pdf" class="tooltips" title="Download" target="_blank">
                                                               <i class="icon-file-text-alt"></i>
                                                           </a>
                                                       </div>
                                                       <span id="publications-list">
                                                         <ul class"list-unstyled-left">
                                                           <li>
                                                             <!--<div class="publication-inpress">2023 <br>(To appear)</div>-->
      			                                                 <div class="publication-year">2023</div>
                                                       <h4 class="pubtitle">Spatial transformer generative adversarial network for image super-resolution</h4>
                                                       <div class="pubauthor">P. Rempakos, <strong>M. Vrigkas</strong>, M.E. Plissiti, C. Nikou</div>
                                                       <div class="pubcite"><span class="label label-danger">Conference Paper</span> 22nd International Conference on Image Analysis and Processing (ICIAP '23), pp. 399-411, Udine, Italy, September 11-15, 2023</div>
                                                   </div>
                                                   <div class="pubdetails">
                                                       <h4>Abstract</h4>
                                                       <div class="span-boxcolor">
                                                       <p align="justify">
                                                         High-resolution images play an essential role in the performance of image analysis and pattern recognition methods. However, the expensive setup required to generate them and the inherent limitations of the sensors in optics manufacturing technology leads to the restricted availability of these images. In this work, we exploit the information retrieved in feature maps using the notable VGG networks and apply a transformer network to address spatial rigid affine transformation invariances, such as translation, scaling, and rotation. To evaluate and compare the performance of the model, three publicly available datasets were used. The model achieved very gratifying and accurate performance in terms of image PSNR and SSIM metrics against the baseline method.
                                                       </p>
                                                       </div>
                                                       <br>
                                                       <h4>BibTex</h4>
                                                       <pre xml:space="preserve">
@inproceedings{Rempakos_et_al_ICIAP23,
author    = {Pantelis Rempakos and Michalis Vrigkas and Marina E. Plissiti and Christophoros Nikou},
title     = {Spatial Transformer Generative Adversarial Network for Image Super-Resolution},
booktitle = {Proc. 22nd International Conference on Image Analysis and Processing},
address   = {Udine, Italy},
pages     = {399--411},
month     = {September},
year      = {2023},
doi       = {10.1007/978-3-031-43148-7_34}
}</pre>
                                                           </li>
                                                         </ul>
                                                       </div>
                                                   </span>
                                               </div>

                                              <!--ICASSP 2023-->
                                               <div class="item mix cpaper 2023" data-year="2023">
                                                   <div class="pubmain">
                                                       <div class="pubassets">
                                                           <a href="https://ieeexplore.ieee.org/abstract/document/10095575" class="tooltips" title="External link" target="_blank">
                                                               <i class="icon-external-link"></i>
                                                           </a>
                                                           <a href="publications/Conferences/C18_ICASSP_2023_RhodesIsland.pdf" class="tooltips" title="Download" target="_blank">
                                                               <i class="icon-file-text-alt"></i>
                                                           </a>
                                                       </div>
                                                       <span id="publications-list">
                                                         <ul class"list-unstyled-left">
                                                           <li>
                                                             <!--<div class="publication-inpress">2023 <br>(To appear)</div>-->
      			                                                  <div class="publication-year">2023</div>
                                                       <h4 class="pubtitle">Composition of motion from video animation through learning local transformations</h4>
                                                       <div class="pubauthor"><strong>M. Vrigkas</strong>, V. Tagka, M.E. Plissiti, C. Nikou</div>
                                                       <div class="pubcite"><span class="label label-danger">Conference Paper</span> IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP '23), pp. 1-5, Rhodes Island, Greece, June 4-10, 2023</div>
                                                   </div>
                                                   <div class="pubdetails">
                                                       <h4>Abstract</h4>
                                                       <div class="span-boxcolor">
                                                       <p align="justify">
                                                         In this work, we solve the problem of motion representation in videos, according to local transformations applied to specific keypoints extracted from static the images. First, we compute the coordinates of the keypoints of the body or face through a pre-trained model, and then we introduce a convolutional neural network to estimate a dense motion field through optical flow. Next, we train a generative adversarial network that exploits the previous information to generate new images that resemble as much as possible the target frames. To reduce trembling and extract smooth movements, our model incorporates a low-pass spatio-temporal Gaussian filter. Results indicate that our method provides high performance and the movement of objects is accurate and robust.
                                                       </p>
                                                       </div>
                                                       <br>
                                                       <h4>BibTex</h4>
                                                       <pre xml:space="preserve">
@inproceedings{MVrigkas_etal_ICASSP_23,
author    = {Michalis Vrigkas and Virginia Tagka and Marina E. Plissiti and Christophoros Nikou},
title     = {Composition of motion from video animation through learning local transformations},
booktitle = {Proc. IEEE International Conference on Acoustics, Speech and Signal Processing},
address   = {Rhodes Island, Greece},
pages     = {1--5},
month     = {June},
year      = {2023}
}</pre>
                                                           </li>
                                                         </ul>
                                                       </div>
                                                   </span>
                                               </div>

                                               <!--ICDEc 2023-->
                                                <div class="item mix cpaper 2023" data-year="2023">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://link.springer.com/chapter/10.1007/978-3-031-42788-6_16" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            <a href="publications/Conferences/C17-ICDEc-2023-Portugal.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-file-text-alt"></i>
                                                            </a>
                                                        </div>
                                                        <span id="publications-list">
                                                          <ul class"list-unstyled-left">
                                                            <li>
       			                                                  <div class="publication-year">2023</div>
                                                        <h4 class="pubtitle">Consumer experience and augmented reality wine label application</h4>
                                                        <div class="pubauthor">A. Triantafillidou, <strong>M. Vrigkas</strong>, A. Kleftodimos, A. Yannacopoulou, M. Matsiola, S. Gkoutzios, G. Lappas</div>
                                                        <div class="pubcite"><span class="label label-danger">Conference Paper</span> 8th International Conference on Digital Economy (ICDEc '23), pp. 263273, Braga, Portugal, May 2-4, 2023</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <div class="span-boxcolor">
                                                        <p align="justify">
                                                          Augmented reality (AR) applications are regarded as effective experiential marketing practices that can help companies promote their products/services in an interactive manner and deliver exceptional consumer experiences. The purpose of the present study is to evaluate a wine-label AR mobile application by examining its impact on consumer experience dimensions, satisfaction, and re-usage intentions towards the application, as well as attitude and purchase intentions towards the wine product. Moreover, to test the effect of product-consumption related factors (consumption frequency, amount of spending, wine expertise, and attention to wine labels) and technology-related factors (consumers familiarity with smartphone applications, number of AR applications used in smartphone, and extent of information search for wine-related information through smartphones) on the experiential dimensions of entertainment, flow, escapism, and education. Towards this end, a wine AR label application was developed and evaluated using a quantitative survey. In total, 306 respondents answered a self-administered questionnaire after interacting with the application. Results indicate that the AR application induced the entertainment and educational dimensions of consumer experience. The AR experience was also able to increase respondents satisfaction with the application and in turn help them form positive attitudes and purchase intentions for the wine. Moreover, the present study revealed that respondents expertise for wine, attention to wine label, familiarity with smartphone applications, and information search for wine-related information through smartphones are important factors that have an impact on the experience lived by consumers when using the AR label application.
                                                        </p>
                                                        </div>
                                                        <br>
                                                        <h4>BibTex</h4>
                                                        <pre xml:space="preserve">
 @inproceedings{ICDEc23,
 author    = {A. Triantafillidou and M. Vrigkas and A. Kleftodimos and A. Yannacopoulou and M. Matsiola and S. Gkoutzios and G. Lappas},
 title     = {Consumer experience and augmented reality wine label application},
 booktitle = {Proc. 8th International Conference on Digital Economy},
 address   = {Braga, Portugal},
 pages     = {263--273},
 month     = {May},
 year      = {2023},
 doi       = {10.1007/978-3-031-42788-6_16}
 }</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                    </span>
                                                </div>


                                               <!--Journal of Microscopy 2023-->
                                               <div class="item mix jpaper 2023" data-year="2023">
                                                   <div class="pubmain">
                                                       <div class="pubassets">
                                                           <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/jmi.13150" class="tooltips" title="External link" target="_blank">
                                                               <i class="icon-external-link"></i>
                                                           </a>
                                                           <a href="publications/Journals/J12_Vrigkas_JM_2023.pdf" class="tooltips" title="Download" target="_blank">
                                                               <i class="icon-file-text-alt"></i>
                                                           </a>
                                                       </div>
                                                       <span id="publications-list">
                                                         <ul class"list-unstyled-left">
                                                           <li>
   				                                                  <div class="publication-year">2023</div>
                                                       <h4 class="pubtitle">Segmentation of SEM images of multiphase materials: When Gaussian mixture models are accurate?</h4>
                                                       <div class="pubauthor">M. Chatzigeorgiou, <strong>M. Vrigkas</strong>, M. Beazi-Katsioti, M. Katsiotis, N. Boukos, V. Constantoudis</div>
                                                       <div class="pubcite"><span class="label label-success">Journal Paper</span>Journal of Microscopy, vol. 289, no. 1, pp. 58-70, January 2023.</div>
                                                   </div>
                                                   <div class="pubdetails">
                                                       <h4>Abstract</h4>
                                                       <div class="span-boxcolor">
                                                       <p align="justify">
                                                         Scanning Electron Microscopy (SEM) have found prosperous ground in the characterization of multiphase materials. One of the fastest modes of SEM with the ability of distinguish different phases is Back-Scattered Electron (BSE) imaging. As an imaging technique, however, the application of a segmentation method is required for the extraction of quantitative results. A very common segmentation technique is based on Gaussian Mixture Models algorithm. This algorithm is able to deconvolute the image histogram into different distributions attributed to different phases of the material. In this work a systematic study on the evaluation of GMM accuracy and an investigation of its limitation is conducted. Towards this investigation, a framework of synthetic BSE image histograms has been conducted for the control of parameters that correlate sample composition and image acquisition setting. The application of this framework is realized for the calculation of the impact of collective parameters of image histogram on the accuracy of GMM deconvolution. To this end some rules of thump are extracted for the guidance of SEM user on the prediction of GMM accuracy based on the inspection of image histogram only. These rule of thump can me summarized if one can distinguish the number of peaks in the histogram equal to the number of gaussian component taking part in GMM. If this is not the case, statistical moments, kurtosis and skewness, can be used in order to differentiate a histogram suitable for an accurate GMM deconvolution from non-suitable ones.
                                                       </p>
                                                       </div>
                                                       <br>
                                                       <h4>BibTex</h4>
                                                       <pre xml:space="preserve">
 @article{MChatzigeorgiou_etal_JM_23,
 author    = {Manolis Chatzigeorgiou and Michalis Vrigkas and Margarita Beazi-Katsiotiand Marios Katsiotis and Nikos Boukos and Vassilios Constantoudis},
 title     = {Segmentation of SEM images of multiphase materials: When Gaussian mixture models are accurate?},
 journal   = {Journal of Microscopy},
 volume    = {289},
 number    = {1},
 pages     = {58--70},
 month     = {January},
 year      = {2023},
 doi       = {https://doi.org/10.1111/jmi.13150}
 }</pre>
                                                           </li>
                                                         </ul>
                                                       </div>
                                                   </span>
                                               </div>

                                              <!--JETM_2 2022-->
                                              <div class="item mix jpaper 2022" data-year="2022">
                                                  <div class="pubmain">
                                                      <div class="pubassets">
                                                          <a href="https://www.inderscience.com/info/inarticle.php?artid=129631" class="tooltips" title="External link" target="_blank">
                                                              <i class="icon-external-link"></i>
                                                          </a>
                                                          <a href="publications/Journals/J11_Vrigkas_JETM_2022.pdf" class="tooltips" title="Download" target="_blank">
                                                              <i class="icon-file-text-alt"></i>
                                                          </a>
                                                      </div>
                                                      <span id="publications-list">
                                                        <ul class"list-unstyled-left">
                                                          <li>
                                                            <!--<div class="publication-inpress">2022 <br>(In press)</div>-->
  				                                                  <div class="publication-year">2022</div>
                                                      <h4 class="pubtitle">An augmented reality workflow for creating &ldquo;live&rdquo; wine labels</h4>
                                                      <div class="pubauthor"><strong>M. Vrigkas</strong>, A. Kleftodimos, G. Lappas</div>
                                                      <div class="pubcite"><span class="label label-success">Journal Paper</span>International Journal of Entertainment Technology and Management, vol. 1, no. 4, pp. 311327, January 2022.</div>
                                                  </div>
                                                  <div class="pubdetails">
                                                      <h4>Abstract</h4>
                                                      <div class="span-boxcolor">
                                                      <p align="justify">
                                                        Augmented reality (AR) technologies are constantly developing in various fields of communication such as entertainment, education, information, and marketing and other fields such as industrial product design among others. This paper aims to present an integrated AR workflow for the labelling of wine products. The proposed wine label enhancement workflow may work as follows: The wine business comes up with the idea of creating an AR experience for its wine products, then an AR expert designs the AR experience, and develops the AR application. As a final step in the process, the application is distributed to the users with the use of various platforms and the experience can then be activated by pointing the camera of a mobile device to the bottle label. The AR content is then generated and displayed to the user who can interact with the digital product on a whole new level.
                                                      </p>
                                                      </div>
                                                      <br>
                                                      <h4>BibTex</h4>
                                                      <pre xml:space="preserve">
@article{MVrigkas_etal_JM_23,
author    = {Michalis Vrigkas and Alexandros Kleftodimos and Georgios Lappas },
title     = {An augmented reality workflow for creating ``live'' wine labels},
journal   = {International Journal of Entertainment Technology and Management},
volume    = {1},
number    = {4},
pages     = {311--327},
month     = {January},
year      = {2022},
doi       = {10.1504/IJENTTM.2022.10054762}
}</pre>
                                                          </li>
                                                        </ul>
                                                      </div>
                                                  </span>
                                              </div>

                                              <!--JETM 2022-->
                                              <div class="item mix jpaper 2022" data-year="2022">
                                                  <div class="pubmain">
                                                      <div class="pubassets">
                                                          <a href="https://www.inderscience.com/info/inarticle.php?artid=129630" class="tooltips" title="External link" target="_blank">
                                                              <i class="icon-external-link"></i>
                                                          </a>
                                                          <a href="publications/Journals/J10_JETM_2022.pdf" class="tooltips" title="Download" target="_blank">
                                                              <i class="icon-file-text-alt"></i>
                                                          </a>
                                                      </div>
                                                      <span id="publications-list">
                                                        <ul class"list-unstyled-left">
                                                          <li>
                                                            <!--<div class="publication-inpress">2022 <br>(In press)</div>-->
  				                                                  <div class="publication-year">2022</div>
                                                      <h4 class="pubtitle">Taleblazer vs Metaverse: A comparative analysis of the two platforms for building AR location-based educational experiences</h4>
                                                      <div class="pubauthor">A. Kleftodimos, G. Lappas, <strong>M. Vrigkas</strong></div>
                                                      <div class="pubcite"><span class="label label-success">Journal Paper</span>International Journal of Entertainment Technology and Management, vol. 1, no. 4, pp. 290310, January 2022.</div>
                                                  </div>
                                                  <div class="pubdetails">
                                                      <h4>Abstract</h4>
                                                      <div class="span-boxcolor">
                                                      <p align="justify">
                                                        Location-based AR games are becoming increasingly popular in education. With location-based AR games, learners can obtain knowledge by visiting places of educational value through informative digital content that is activated and displayed on their mobile devices when specific locations are reached. To create location-based AR games, there are several available authoring tools. Taleblazer and Metaverse Studio are two popular platforms that are used nowadays by many educators. This study aims to perform a comparative analysis between these platforms to provide educators interested in developing location-based AR experiences with all the information needed to make an informed decision on which platform to use. The analysis examines the designer environment and its available features, the end-user interface, the documentation that accompanies each platform, and third-party applications that are developed by these tools. Furthermore, two game prototypes have been developed to better understand the two platforms functionality.
                                                      </p>
                                                      </div>
                                                      <br>
                                                      <h4>BibTex</h4>
                                                      <pre xml:space="preserve">
@article{Kleftodimos_etal_JM_23,
author    = {Alexandros Kleftodimos and Georgios Lappas and Michalis Vrigkas},
title     = {Taleblazer vs Metaverse: A comparative analysis of the two platforms for building AR location-based educational experiences},
journal   = {International Journal of Entertainment Technology and Management},
volume    = {1},
number    = {4},
pages     = {290--310},
month     = {January},
year      = {2022},
doi       = {10.1504/IJENTTM.2022.10054761}
}</pre>
                                                          </li>
                                                        </ul>
                                                      </div>
                                                  </span>
                                              </div>

                                              <!--SETN 2022-->
                                               <div class="item mix cpaper 2022" data-year="2022">
                                                   <div class="pubmain">
                                                       <div class="pubassets">
                                                           <a href="https://dl.acm.org/doi/abs/10.1145/3549737.3549800" class="tooltips" title="External link" target="_blank">
                                                               <i class="icon-external-link"></i>
                                                           </a>
                                                           <a href="publications/Conferences/C16_SETN_AINST_2022_Corfu.pdf" class="tooltips" title="Download" target="_blank">
                                                               <i class="icon-file-text-alt"></i>
                                                           </a>
                                                       </div>
                                                       <span id="publications-list">
                                                         <ul class"list-unstyled-left">
                                                           <li>
                                                             <!--<div class="publication-inpress">2021 <br>(To appear)</div>-->
      			                                                  <div class="publication-year">2022</div>
                                                       <h4 class="pubtitle">Machine learning evaluation of microscopy image segmentation methods: The case of Gaussian mixture models</h4>
                                                       <div class="pubauthor">M. Chatzigeorgiou, <strong>M. Vrigkas</strong>, N. Boukos, M. Beazi-Katsioti, M. Katsiotis and V. Constantoudis</div>
                                                       <div class="pubcite"><span class="label label-danger">Conference Paper</span> 12<sup>th</sup> Hellenic Conference on Artificial Intelligence (SETN '22). Association for Computing Machinery, New York, NY, USA, Article 59, 14, Corfu, Greece, September 7-9, 2022</div>
                                                   </div>
                                                   <div class="pubdetails">
                                                       <h4>Abstract</h4>
                                                       <div class="span-boxcolor">
                                                       <p align="justify">
                                                         Multiphase materials are encountered in several areas of science and technology. Their properties are determined by the fraction of the phases (material compounds) constituting the composite material. Therefore, the quantitative characterization of phase fractions is highly demanded and has been the subject of extensive studies. To this end, a widely used technique is the segmentation of top-down back-scattered electron SEM (BSE-SEM) images given that different phases are depicted with pixel collections of different luminosity. Gaussian mixture models (GMM) are one the most popular and easily implemented methods to segment the BSE-SEM images through the deconvolution of their histograms. However, the accuracy and the limitations of their application have not been fully investigated. The aim of this paper is to design a neural-network approach to fill this gap and provide a fast tool for the automatic evaluation of the accuracy of GMM predictions for all material phases based on the inspection of the measured SEM image histogram alone. The proposed tool facilitates the decision-making process of an SEM user concerning the optimum choice of a segmentation method.
                                                       </p>
                                                       </div>
                                                       <br>
                                                       <h4>BibTex</h4>
                                                       <pre xml:space="preserve">
@inproceedings{MChatzigeorgiou_etal_SETN_22,
author    = {Manolis Chatzigeorgiou and Michalis Vrigkas and Nikos Boukos and Margarita Beazi-Katsioti and Marios Katsiotis and Vassilios Constantoudis},
title     = {Machine learning evaluation of microscopy image segmentation methods: The case of Gaussian mixture models},
booktitle = {Proc. 12th Hellenic Conference on Artificial Intelligence},
address   = {Corfu, Greece},
articleno = {59},
numpages  = {4},
doi       = {10.1145/3549737.3549800},
month     = {September},
year      = {2022},
series    = {SETN '22}
}</pre>
                                                           </li>
                                                         </ul>
                                                       </div>
                                                   </span>
                                               </div>

                                              <!--Sensors 2022-->
                                              <div class="item mix jpaper 2022" data-year="2022">
                                                  <div class="pubmain">
                                                      <div class="pubassets">
                                                          <a href="https://www.mdpi.com/1424-8220/22/3/896/htm" class="tooltips" title="External link" target="_blank">
                                                              <i class="icon-external-link"></i>
                                                          </a>
                                                          <a href="publications/Journals/J9_Vrigkas_Sensors_2022.pdf" class="tooltips" title="Download" target="_blank">
                                                              <i class="icon-file-text-alt"></i>
                                                          </a>
                                                      </div>
                                                      <span id="publications-list">
                                                        <ul class"list-unstyled-left">
                                                          <li>
  				                                                  <div class="publication-year">2022</div>
                                                      <h4 class="pubtitle">FaceMask: A new image dataset for the automated identification of people wearing masks in the wild</h4>
                                                      <div class="pubauthor"><strong>M. Vrigkas</strong>, E-A. Kourfalidou, M.E. Plissiti, C. Nikou</div>
                                                      <div class="pubcite"><span class="label label-success">Journal Paper</span>Sensors, vol. 22, no. 3, 896, January 2022.</div>
                                                  </div>
                                                  <div class="pubdetails">
                                                      <h4>Abstract</h4>
                                                      <div class="span-boxcolor">
                                                      <p align="justify">
                                                        The rapid spread of the COVID-19 pandemic, in early 2020, has radically changed the lives of people. In our daily routine, the use of a face (surgical) mask is necessary, especially in public places, to prevent the spread of this disease. Furthermore, in crowded indoor areas, the automated recognition of people wearing a mask is a requisite for the assurance of public health. In this direction, image processing techniques, in combination with deep learning, provide effective ways to deal with this problem. However, it is a common phenomenon that well-established datasets containing images of people wearing masks are not publicly available. To overcome this obstacle and to assist the research progress in this field, we present a publicly available annotated image database containing images of people with and without a mask on their faces, in different environments and situations. Moreover, we tested the performance of deep learning detectors in images and videos on this dataset. The training and the evaluation were performed on different versions of the YOLO network using Darknet, which is a state-of-the-art real-time object detection system. Finally, different experiments and evaluations were carried out for each version of YOLO, and the results for each detector are presented.
                                                      </p>
                                                      </div>
                                                      <br>
                                                      <h4>BibTex</h4>
                                                      <pre xml:space="preserve">
@article{MVrigkas_etal_22,
author          = {Michalis Vrigkas and Evangelia-Andriana Kourfalidou and Marina E. Plissiti and Christophoros Nikou},
title           = {FaceMask: A new image dataset for the automated identification of people wearing masks in the wild},
journal         = {Sensors},
volume          = {22},
number          = {3},
article-number  = {896},
month           = {January},
year            = {2022},
doi             = {https://doi.org/10.3390/s22030896}
}</pre>
                                                          </li>
                                                        </ul>
                                                      </div>
                                                  </span>
                                              </div>

                                              <!--PAA 2021-->
                                              <div class="item mix jpaper 2021" data-year="2021">
                                                  <div class="pubmain">
                                                      <div class="pubassets">
                                                          <a href="https://link.springer.com/article/10.1007/s10044-020-00953-x" class="tooltips" title="External link" target="_blank">
                                                              <i class="icon-external-link"></i>
                                                          </a>
                                                          <a href="publications/Journals/J8_Vrigkas_PAA_2021.pdf" class="tooltips" title="Download" target="_blank">
                                                              <i class="icon-file-text-alt"></i>
                                                          </a>
                                                      </div>
                                                      <span id="publications-list">
                                                        <ul class"list-unstyled-left">
                                                          <li>
                                                            <!--<div class="publication-inpress">2021 <br>(In press)</div>-->
  				                                                  <div class="publication-year">2021</div>
                                                      <h4 class="pubtitle">Human activity recognition using robust adaptive privileged probabilistic learning</h4>
                                                      <div class="pubauthor"><strong>M. Vrigkas</strong>, E. Kazakos, C. Nikou, I.A. Kakadiaris</div>
                                                      <div class="pubcite"><span class="label label-success">Journal Paper</span>Pattern Analysis and Applications, vol. 24, no. 3, pp. 915-932, January 2021.</div>
                                                  </div>
                                                  <div class="pubdetails">
                                                      <h4>Abstract</h4>
                                                      <div class="span-boxcolor">
                                                      <p align="justify">
                                                        In this work, a supervised probabilistic approach is proposed that integrates the learning using privileged information (LUPI) paradigm into a hidden conditional random field (HCRF) model, called HCRF+, for human action recognition. The proposed model employs a self-training technique for automatic estimation of the regularization parameters of the objective function. Moreover, the method provides robustness to outliers by modeling the conditional distribution of the privileged information by a Student's <i>t</i>-density function, which is naturally integrated into the HCRF+ framework. The proposed method was evaluated using different forms of privileged information on four publicly available datasets.  The experimental results demonstrate its effectiveness concerning the-state-of-the-art in the LUPI framework using both hand-crafted and deep learning-based features extracted from a convolutional neural network.
                                                      </p>
                                                      </div>
                                                      <br>
                                                      <h4>BibTex</h4>
                                                      <pre xml:space="preserve">
@article{MVrigkas_etal_21,
author    = {Michalis Vrigkas and Evangelos Kazakos and Christophoros Nikou and Ioannis A. Kakadiaris},
title     = {Human activity recognition using robust adaptive privileged probabilistic learning},
journal   = {Pattern Analysis and Applications},
volume    = {24},
number    = {3},
pages     = {915-932},
month     = {January},
year      = {2021},
doi       = {https://doi.org/10.1007/s10044-020-00953-x}
}</pre>
                                                          </li>
                                                        </ul>
                                                      </div>
                                                  </span>
                                              </div>

                                        <!--ETLTC 2021-->
                                         <div class="item mix cpaper 2021" data-year="2021">
                                             <div class="pubmain">
                                                 <div class="pubassets">
                                                     <a href="https://www.shs-conferences.org/articles/shsconf/abs/2021/13/shsconf_etltc2021_04006/shsconf_etltc2021_04006.html" class="tooltips" title="External link" target="_blank">
                                                         <i class="icon-external-link"></i>
                                                     </a>
                                                     <a href="publications/Conferences/C15_ETLTC_2021_Aizu.pdf" class="tooltips" title="Download" target="_blank">
                                                         <i class="icon-file-text-alt"></i>
                                                     </a>
                                                 </div>
                                                 <span id="publications-list">
                                                   <ul class"list-unstyled-left">
                                                     <li>
                                                       <!--<div class="publication-inpress">2021 <br>(To appear)</div>-->
			                                                  <div class="publication-year">2021</div>
                                                 <h4 class="pubtitle">Augmented Reality for Wine Industry: Past, Present, and Future</h4>
                                                 <div class="pubauthor"><strong>M. Vrigkas</strong>, G. Lappas, A. Kleftodimos, A. Triantafillidou</div>
                                                 <div class="pubcite"><span class="label label-danger">Conference Paper</span>3<sup>rd</sup> ETLTC International Conference on Information and Communications Technology, pp.04006, Aizuwakamatsu Japan, January 27-30 2021</div>
                                             </div>
                                             <div class="pubdetails">
                                                 <h4>Abstract</h4>
                                                 <div class="span-boxcolor">
                                                 <p align="justify">
                                                   In this paper, we study the concepts, materials, tools, and applications that constitute what we call augmented reality (AR) for the wine industry. A comprehensive review of what are the basic multimedia content and the minimum algorithmic requirements used to implement successful AR applications for wine products is given. To this end, we provide a detailed analysis of how AR technology is used to create augmented live wine labels, and how digital storytelling has revolutionized wine products marketing. Also, we describe the use of AR technology to promote winemaking companies to influence consumer preferences. Finally, we report the characteristics of future research directions and some open issues and challenges on using AR for wine product promotion.
                                                 </p>
                                                 </div>
                                                 <br>
                                                 <h4>BibTex</h4>
                                                 <pre xml:space="preserve">
@inproceedings{MVrigkas_etal_ETLTC_21,
author    = {Michalis Vrigkas and Georgios Lappas and Alexandros Kleftodimos and Amalia Triantafillidou},
title     = {Augmented Reality for Wine Industry: Past, Present, and Future},
booktitle = {3rd International Conference on Information and Communications Technology},
address   = {Aizuwakamatsu Japan},
pages     = {04006},
month     = {January},
year      = {2021},
doi       = {10.1051/shsconf/202110204006}
}</pre>
                                                     </li>
                                                   </ul>
                                                 </div>
                                             </span>
                                         </div>

					                                   <!--ISVC 2020-->
                                              <div class="item mix cpaper 2020" data-year="2020">
                                                  <div class="pubmain">
                                                      <div class="pubassets">
                                                          <a href="https://link.springer.com/chapter/10.1007/978-3-030-64556-4_38" class="tooltips" title="External link" target="_blank">
                                                              <i class="icon-external-link"></i>
                                                          </a>
                                                          <a href="publications/Conferences/C14_ISVC_2020_Virtual.pdf" class="tooltips" title="Download" target="_blank">
                                                              <i class="icon-file-text-alt"></i>
                                                          </a>
                                                      </div>
                                                      <span id="publications-list">
                                                        <ul class"list-unstyled-left">
                                                          <li>
                                                            <!--<div class="publication-inpress">2020 <br>(To appear)</div>-->
					                                                  <div class="publication-year">2020</div>
                                                      <h4 class="pubtitle">Gender and age estimation without facial information from still images</h4>
                                                      <div class="pubauthor">G. Chatzitzisi, <strong>M. Vrigkas</strong>, C. Nikou</div>
                                                      <div class="pubcite"><span class="label label-danger">Conference Paper</span>15<sup>th</sup> International Symposioum on Visual Computing, pp.488-500, October 5-7 2020</div>
                                                  </div>
                                                  <div class="pubdetails">
                                                      <h4>Abstract</h4>
                                                      <div class="span-boxcolor">
                                                      <p align="justify">
                                                        In this paper, the task of gender and age recognition is performed on pedestrian still images, which are usually captured in-the-wild with no near face-frontal information. Moreover, another difficulty originates from the underlying class imbalance in real examples, especially for the age estimation problem. The scope of the paper is to examine how different loss functions in convolutional neural networks (CNN) perform under the class imbalance problem. For this purpose, as a backbone, we employ the Residual Network (ResNet). On top of that, we attempt to benefit from appearance-based attributes, which are inherently present in the available data. We incorporate this knowledge in an autoencoder, which we attach to our baseline CNN for the combined model to jointly learn the features and increase the classification accuracy. Finally, all of our experiments are evaluated on two publicly available datasets.
                                                      </p>
                                                      </div>
                                                      <br>
                                                      <h4>BibTex</h4>
                                                      <pre xml:space="preserve">
@inproceedings{GChatzitzisi_etal_20,
author    = {Georgia Chatzitzisi and Michalis Vrigkas and Christophoros Nikou},
title     = {Gender and age estimation without facial information from still images},
booktitle = {International Symposioum on Visual Computing},
publisher = {Springer International Publishing},
address   = {San Diego, CA},
pages     = {488-500},
month     = {October},
year      = {2020},
isbn      = {978-3-030-64556-4}
}</pre>
                                                          </li>
                                                        </ul>
                                                      </div>
                                                  </span>
                                              </div>

						                                   <!--EI 2020-->
                                                <div class="item mix cpaper 2020" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://doi.org/10.2352/ISSN.2470-1173.2020.10.IPAS-063" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            <a href="publications/Conferences/C13_EI_2020_SanFransisco.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-file-text-alt"></i>
                                                            </a>
                                                        </div>
                                                        <span id="publications-list">
                                                          <ul class"list-unstyled-left">
                                                            <li>
                                                              <!--<div class="publication-inpress">2020 <br>(To appear)</div>-->
						                                                  <div class="publication-year">2020</div>
                                                        <h4 class="pubtitle">Improving 3D medical image compression efficiency using spatiotemporal coherence</h4>
                                                        <div class="pubauthor">M.C. Zerva, <strong>M. Vrigkas</strong>, L.P. Kondi, C. Nikou</div>
                                                        <div class="pubcite"><span class="label label-danger">Conference Paper</span>IS&T International Symposioum on Electronic Imaging, Image Processing: Algorithms and Systems XVII, Burlingame, CA, USA, January 26-30 2020</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <div class="span-boxcolor">
                                                        <p align="justify">
                                                          Advanced methodologies for transmitting compressed images, within acceptable ranges of transmission rate and loss of information, make it possible to transmit a medical image through a communication channel. Most prior works on 3D medical image compression consider volumetric images as a whole but fail to account for the spatial and temporal coherence of adjacent slices. In this paper, we set out to develop a 3D medical image compression method that extends the 3D wavelet difference reduction algorithm by computing the similarity of the pixels in adjacent slices and progressively compress only the similar slices. The proposed method achieves high-efficiency performance on publicly available datasets of MRI scans by achieving compression down to one bit per voxel with PSNR and SSIM up to 52.3 dB and 0.7578, respectively.
                                                        </p>
                                                        </div>
                                                        <br>
                                                        <h4>BibTex</h4>
                                                        <pre xml:space="preserve">
@inproceedings{MZerva_etal_20,
  author    = {Matina Ch. Zerva and Michalis Vrigkas and Lisimachos P. Kondi and Christophoros Nikou},
  title     = {Improving {3D} medical image compression efficiency using spatiotemporal coherence},
  booktitle = {Proc. IS&T International Symposioum on Electronic Imaging, Image Processing: Algorithms and Systems XVII},
  pages     = {63-1-63-6},
  address   = {Burlingame, CA},
  month     = {January},
  year 	    = {2020}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                    </span>
                                                </div>

                                              <!--ICIP 2019-->
                                                <div class="item mix cpaper 2019" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://ieeexplore.ieee.org/abstract/document/8802916" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            <a href="publications/Conferences/C12_ICIP_2019_Taipei.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-file-text-alt"></i>
                                                            </a>
                                                        </div>
                                                        <span id="publications-list">
                                                          <ul class"list-unstyled-left">
                                                            <li>
														<div class="publication-year">2019</div>
                                                        <h4 class="pubtitle">RECASPIA: Recognizing carrying actions in single images using privileged information</h4>
                                                        <div class="pubauthor">C. Smailis, <strong>M. Vrigkas</strong>, I.A. Kakadiaris</div>
                                                        <div class="pubcite"><span class="label label-danger">Conference Paper</span>26<sup>th</sup> International Conference on Image Processing, pp. 26-30, Taipei, Taiwan, September 22-25 2019</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <div class="span-boxcolor">
                                                        <p align="justify">
                                                          Many approaches for action recognition focus on general actions, such as &ldquo;running&rdquo; or &ldquo;walking&rdquo;. This work presents a method for recognizing carrying actions in single images, by utilizing privileged information, such as annotations, available only during training, following the learning using privileged information paradigm. In addition, we introduce a dataset for carrying actions, formed using images extracted from YouTube videos depicting several scenarios. We accompany the dataset with a variety of different annotation types that include human pose, object and scene attributes. The experimental results demonstrate that our method, boosted sample averaged F1 score performance by 15.4% and 4.15% respectively, in the validation and testing partitions of our dataset, when compared to an end-to-end CNN model, trained only with observable information.
                                                        </p>
                                                        </div>
                                                        <br>
                                                        <h4>BibTex</h4>
                                                        <pre xml:space="preserve">
@inproceedings{CSmailis_ICIP19,
  author    = {Christos Smailis and Michalis Vrigkas and Ioannis A. Kakadiaris},
  title     = {RECASPIA: Recognizing carrying actions in single images using privileged information},
  booktitle = {Proc. 26th IEEE International Conference on Image Processing},
  pages     = {26--30},
  address   = {Taipei, Taiwan},
  month     = {September},
  year 	    = {2019}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                    </span>
                                                </div>

                                              <!--ISVC 2018-->
                                                <div class="item mix cpaper 2018" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://link.springer.com/chapter/10.1007/978-3-030-03801-4_12" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            <a href="publications/Conferences/C11_ISVC_2018_LasVegas.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-file-text-alt"></i>
                                                            </a>
                                                        </div>
                                                        <span id="publications-list">
                                                          <ul class"list-unstyled-left">
                                                            <li>
                                                              <!--<div class="publication-inpress">2018 <br>(To appear)</div>-->
					                                                    <div class="publication-year">2018</div>
                                                        <h4 class="pubtitle">Robust incremental hidden conditional random fields for human action recognition</h4>
                                                        <div class="pubauthor"><strong>M. Vrigkas</strong>, E. Mastora, C. Nikou, I.A. Kakadiaris</div>
                                                        <div class="pubcite"><span class="label label-danger">Conference Paper</span>13<sup>th</sup> International Symposium on Visual Computing, pp. 126-136, Las Vegas, NV, November 19-21 2018</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <div class="span-boxcolor">
                                                        <p align="justify">
                                                          Hidden conditional random fields (HCRFs) are a powerful supervised classification system, which is able to capture the intrinsic motion patterns of a human action. However, finding the optimal number of hidden states remains a severe limitation for this model. This paper addresses this limitation by proposing a new model, called robust incremental hidden conditional random field (RI-HCRF). A hidden Markov model (HMM) is created for each observation paired with an action label and its parameters are defined by the potentials of the original HCRF graph. Starting from an initial number of hidden states and increasing their number incrementally, the Viterbi path is computed for each HMM. The method seeks for a sequence of hidden states, where each variable participates in a maximum number of optimal paths. Thereby, variables with low participation in optimal paths are rejected. In addition, a robust mixture of Student's <em> t</em>-distributions is imposed as a regularizer to the parameters of the model. The experimental results on human action recognition show that RI-HCRF successfully estimates the number of hidden states and outperforms all state-of-the-art models.
                                                        </p>
                                                        </div>
                                                        <br>
                                                        <h4>BibTex</h4>
                                                        <pre xml:space="preserve">
@inproceedings{MVrigkas_ISVC18,
  author    = {Michalis Vrigkas and Ermioni Mastora and Christophoros Nikou and Ioannis A. Kakadiaris},
  title     = {Robust incremental hidden conditional random fields for human action recognition},
  booktitle = {Proc. 13th International Symposium on Visual Computing},
  address   = {Las Vegas, NV},
  month     = {November},
  pages	    = {126--136},
  year 	    = {2018}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                    </span>
                                                </div>

                                              <!--JAHA 2018-->
                                                <div class="item mix jpaper 2018" data-year="2018">
                                                    <div class="pubmain">
                                                          <div class="pubassets">
                                                        <a href="https://www.ahajournals.org/doi/10.1161/JAHA.118.009476" class="tooltips" title="External link" target="_blank">
                                                            <i class="icon-external-link"></i>
                                                        </a>
                                                        <a href="publications/Journals/J7_JAHA_2018_Suppl.pdf" class="tooltips" title="Supplementary" target="_blank">
                                                            <i class="icon-paperclip"></i>
                                                        </a>
                                                        <a href="publications/Journals/J7_JAHA_2018.pdf" class="tooltips" title="Download" target="_blank">
                                                            <i class="icon-file-text-alt"></i>
                                                        </a>
                                                        </div>
                                                        <span id="publications-list">
                                                          <ul class"list-unstyled-left">
                                                            <li>
                                                              <div class="publication-year">2018</div>
                                                        <h4 class="pubtitle">Machine learning outperforms ACC/AHA CVD risk calculator in MESA</h4>
                                                        <div class="pubauthor">I.A. Kakadiaris, <strong>M. Vrigkas</strong>, A.A. Yen, T. Kuznetsova, M. Budoff, M. Naghavi</div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span>Journal of the American Heart Association, vol. 7, no. 22, pp. e009476, November 2018</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <div class="span-boxcolor">
                                                        <p align="justify">The 2013 ACC/AHA Pooled Cohort Equations risk calculator has been shown to be inaccurate in certain populations. Using the same risk variables, we developed a Machine Learning-based risk calculator in the MESA (Multi-Ethnic Study of Atherosclerosis) cohort and validated in the Flemish Study on Environment, Genes and Health Outcomes (FLEMENGHO). The ML Risk Calculator outperformed the ACC/AHA Risk Calculator by recommending less drug therapy, yet missing fewer CVD events. These findings demonstrate the potential of Machine Learning to assist medical decision-making.</p>
                                                        </div>
                                                        <br>
                                                        <h4>BibTex</h4>
                                                        <pre xml:space="preserve">
@article{Kakadiaris_JAHA18,
  author  = {Ioannis A. Kakadiaris and Michalis Vrigkas and Albert A. Yen and Tatiana Kuznetsova and Matthew Budoff and Morteza Naghavi},
  title   = {Machine learning outperforms {ACC/AHA CVD} risk calculator in {MESA}},
  journal = {Journal of the American Heart Association},
  volume  = {7},
  number  = {22},
  pages   = {e009476},
  year    = {2018},
  month   = {November},
  doi     = {10.1161/JAHA.118.009476}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                    </span>
                                                </div>


												<!-- AHA 2018-->
                                                <div class="item mix cabstract 2018" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="https://www.ahajournals.org/doi/10.1161/circ.138.suppl_1.17154" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            <a href="publications/Abstracts/CA2_Vrigkas_Abstract_AHA_2018.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-file-text-alt"></i>
                                                            </a>
                                                        </div>
                                                        <span id="publications-list">
                                                          <ul class"list-unstyled-left">
                                                            <li>
                                                              <div class="publication-year">2018</div>
                                                        <h4 class="pubtitle">
                                                             Machine learning outperforms ACC/AHA CVD risk calculator in MESA offering new opportunities for short-term risk prediction and early detection of the vulnerable patient
                                                        </h4>
                                                        <div class="pubauthor">I.A. Kakadiaris, <strong>M. Vrigkas</strong>, A.A. Yen, T. Kuznetsova, M. Budoff, M. Naghavi</div>
                                                        <div class="pubcite">
                                                            <span class="label label-abstract">Conference - Abstract</span> Circulation, vol 138, no. Suppl 1, pp. A17154, American Heart Association, Scientific Sessions,  Chicago, IL, November, 2018
                                                        </div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <div class="span-boxcolor">
                                                        <p align="justify">Introduction: Machine learning (ML) is poised to revolutionize healthcare. Current national guidelines for prediction and prevention of atherosclerotic cardiovascular disease (ASCVD) use ACC/AHA Pooled Cohort Equation Risk Calculator which relies on traditional risk factors and linear statistical models. Unfortunately, this approach yields a low level of sensitivity and specificity. The low sensitivity results in missing high-risk individuals who need intensive therapy and the low specificity results in millions of people unnecessarily recommended drugs such as statin. We aimed to utilize Machine Learning (ML) to create a more accurate predictor of ASCVD events and whom to recommend statin.
														<br>
														Methods: We developed and validated a ML Risk Calculator based on Support Vector Machines (SVMs) using the latest 13-year follow up dataset from MESA (Multi-Ethnic Study of Atherosclerosis) of 6,459 participants who were free of cardiovascular disease at baseline. We provided identical input to the ACC/AHA and ML risk calculators and compared their accuracy. We also validated the ML model in another longitudinal cohort: the Flemish Study on Environment, Genes and Health Outcomes (FLEMENGHO).
														<br>
														Results: According to the ACC/AHA Risk Calculator and a 7.5% 10-year risk threshold, 46.0% would be recommended statin. Despite this high proportion, 23.8% of the 480 Hard CVD events occurred in those not recommended statin, resulting in sensitivity (Sn) 0.76, specificity (Sp) 0.56, and AUC 0.71. In contrast, ML Risk Calculator recommended statin to 11.4%, and only 14.4% of Hard CVD events occurred in those not recommended statin, resulting in Sn 0.86, Sp 0.95, and AUC 0.92. Similar results were seen in prediction of All CVD events.
														<br>
														Conclusions: The ML Risk Calculator outperformed the ACC/AHA Risk Calculator by recommending less drug therapy, yet missing fewer events. Additional studies are underway to validate the ML model in other cohorts and to explore its ability in predicting short-term (1-5 years) events with additional biomarkers including imaging. Machine learning is paving the way for early detection of asymptomatic high-risk individuals destined to a CVD event in the near future, the Vulnerable Patient</p>
                                                      </div>
                                                        <br>
                                                        <h4>BibTex</h4>
                                                        <pre xml:space="preserve">
@inproceedings{Kakadiaris_etal18,
  author    = {Ioannis A Kakadiaris and Michail Vrigkas and Albert Yen and Tatiana Kuznetsova and Matthew Budoff and Morteza Naghavi},
  title     = {Machine learning outperforms ACC/AHA CVD risk calculator in MESA offering new opportunities for short-term risk prediction and early detection of the vulnerable patient},
  journal   = {Circulation},
  volume    = {138},
  number    = {Suppl\ 1},
  pages     = {A17154--A17154},
  year      = {2018},
  month     = {November},
  address   = {Chicago, IL},
  publisher = {American Heart Association, Inc.},
  doi       = {10.1161/circ.138.suppl\_1.17154}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                    </span>
                                                </div>

                                              <!--VISSAP 2018-->
                                                <div class="item mix cpaper 2018" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="http://www.scitepress.org/PublicationsDetail.aspx?ID=KigJst78lBc=&t=1" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            <a href="publications/Conferences/C10_VISAPP_2018_Funchal.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-file-text-alt"></i>
                                                            </a>
                                                        </div>
                                                        <span id="publications-list">
                                                          <ul class"list-unstyled-left">
                                                            <li>
                                                              <div class="publication-year">2018</div>
                                                        <h4 class="pubtitle">SPICE: Superpixel classification for cell detection and counting</h4>
                                                        <div class="pubauthor">O. Maga&ntilde;a-Tellez, <strong>M. Vrigkas</strong>, C. Nikou, I.A. Kakadiaris</div>
                                                        <div class="pubcite"><span class="label label-danger">Conference Paper</span> 13<sup>th</sup> International Conference on Computer Vision Theory and Applications pp. 485-490, Funchal, Madeira, Portugal, January 27-29 2018</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <div class="span-boxcolor">
                                                        <p align="justify">An algorithm for the localization and counting of cells in histopathological images is presented. The algorithm relies on the presegmentation of an image into a number of superpixels followed by two random forests for classification. The first random forest determines if there are any cells in the superpixels at its input and the second random forest provides the number of cells in the respective superpixel. The algorithm is evaluated on a bone marrow histopathological dataset. We argue that a single random forest is not sufficient to detect all the cells in the image while a cascade of classifiers achieves higher accuracy. The results compare favorably with the state of the art but with a lower computational cost.</p>
                                                        </div>
                                                        <br>
                                                        <h4>BibTex</h4>
                                                        <pre xml:space="preserve">
@inproceedings{MOman_VISAPP18,
  author    = {Oman Maga\~{n}a-Tellez and Michalis Vrigkas and Christophoros Nikou and Ioannis A. Kakadiaris},
  title     = {SPICE: Superpixel classification for cell detection and counting},
  booktitle = {Proc. 13th International Conference on Computer Vision Theory and Applications},
  address   = {Funchal, Madeira, Portugal},
  month     = {January},
  pages	    = {485--490},
  year 	    = {2018}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                    </span>
                                                </div>

                                                <!-- Circulation 2017-->
                                                <div class="item mix cabstract 2017" data-year="2017">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="http://circ.ahajournals.org/content/136/Suppl_1/A23075" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            <a href="publications/Abstracts/CA1_Vrigkas_Abstract_AHA_2017.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-file-text-alt"></i>
                                                            </a>
                                                        </div>
                                                        <span id="publications-list">
                                                          <ul class"list-unstyled-left">
                                                            <li>
                                                              <div class="publication-year">2017</div>
                                                        <h4 class="pubtitle">
                                                            Machine learning outperformed ACC/AHA Pooled Cohort Equations Risk Calculator for detection of high-risk asymptomatic individuals and recommending treatment for prevention of cardiovascular events in the Multi-Ethnic Study of Atherosclerosis (MESA)
                                                        </h4>
                                                        <div class="pubauthor">I.A. Kakadiaris, <strong>M. Vrigkas</strong>, M. Budoff, A. Yen, M. Naghavi</div>
                                                        <div class="pubcite">
                                                            <span class="label label-abstract">Conference - Abstract</span> Circulation, vol 136, no. Suppl 1, pp. A23075, American Heart Association, Scientific Sessions, Anaheim, CA, November 2017
                                                        </div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <div class="span-boxcolor">
                                                        <p align="justify">Studies have shown that the status quo for atherosclerotic cardiovascular disease (ASCVD) prediction in the U.S. - using ACC/AHA Pooled Cohort Equations Risk Calculator - is inaccurate and results in overtreatment of low-risk and undertreatment of high-risk individuals. Machine Learning (ML) is poised to revolutionize healthcare. We used ML to develop a new ASCVD risk calculator and tackled the problem.</p>
                                                        </div>
                                                        <br>
                                                        <h4>BibTex</h4>
                                                        <pre xml:space="preserve">
@article{IKakadiaris_AHA17,
  author    = {Ioannis Kakadiaris and Michalis Vrigkas and Matthew Budoff and Albert Yen and Morteza Naghavi},
  title     = {Machine learning outperformed {ACC/AHA} {P}ooled {C}ohort {E}quations {R}isk {C}alculator for detection of high-risk asymptomatic individuals and recommending treatment for prevention of cardiovascular events in the {M}ulti-{E}thnic {S}tudy of {A}therosclerosis {(MESA)}},
  volume    = {136},
  number    = {Suppl 1},
  pages     = {A23075--A23075},
  year      = {2017},
  month     = {November 11-15},
  address   = {Anaheim, CA},
  publisher = {American Heart Association, Inc.},
  issn      = {0009-7322},
  URL       = {http://circ.ahajournals.org/content/136/Suppl_1/A23075},
  eprint    = {http://circ.ahajournals.org/content},
  journal   = {Circulation}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                    </span>
                                                </div>

                                                <!--ICCVW_2 2017-->
                                                  <div class="item mix cpaper 2017" data-year="2017">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="https://ieeexplore.ieee.org/document/8265524/" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Conferences/C9_ICCVW_2017_2_Venice.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2017</div>
                                                          <h4 class="pubtitle">Inferring human activities using robust privileged probabilistic learning</h4>
                                                          <div class="pubauthor"><strong>M. Vrigkas</strong>, E. Kazakos, C. Nikou, I.A. Kakadiaris</div>
                                                          <div class="pubcite"><span class="label label-danger">Conference Paper</span>IEEE International Conference on Computer VisionWorkshops, pp. 2658-2665, Venice, Italy, October 22-29 2017</div>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">Classification models may often suffer from &ldquo;structure imbalance&rdquo; between training and testing data that may occur due to the deficient data collection process. This imbalance can be represented by the learning using privileged information (LUPI) paradigm. In this paper, we present a supervised probabilistic classification approach that integrates LUPI into a hidden conditional random field (HCRF) model. The proposed model is called LUPI-HCRF and is able to cope with additional information that is only available during training. Moreover, the proposed method employes Student's <italic>t</italic>-distribution to provide robustness to outliers by modeling the conditional distribution of the privileged information. Experimental results in three publicly available datasets demonstrate the effectiveness of the proposed approach and improve the state-of-the-art in the LUPI framework for recognizing human activities.
                                                          </p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@inproceedings{MVrigkas_ICCVW17,
  author    = {Michalis Vrigkas and Evangelos Kazakos and Christophoros Nikou and Ioannis A. Kakadiaris},
  title     = {Inferring human activities using robust privileged probabilistic learning},
  booktitle = {Proc. IEEE International Conference on Computer Vision Workshops},
  year      = {2017},
  month     = {October},
  pages     = {2658--2665},
  address   = {Venice, Italy}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                  <!--ICCVW 2017-->
                                                    <div class="item mix cpaper 2017" data-year="2017">
                                                        <div class="pubmain">
                                                            <div class="pubassets">
                                                                <a href="https://ieeexplore.ieee.org/document/8265521/" class="tooltips" title="External link" target="_blank">
                                                                    <i class="icon-external-link"></i>
                                                                </a>
                                                                <a href="publications/Conferences/C8_ICCVW_2017_1_Suppl_Venice.pdf" class="tooltips" title="Supplementary" target="_blank">
                                                                    <i class="icon-paperclip"></i>
                                                                </a>
                                                                <a href="publications/Conferences/C8_ICCVW_2017_1_Venice.pdf" class="tooltips" title="Download" target="_blank">
                                                                    <i class="icon-file-text-alt"></i>
                                                                </a>
                                                            </div>
                                                            <span id="publications-list">
                                                              <ul class"list-unstyled-left">
                                                                <li>
                                                                  <div class="publication-year">2017</div>
                                                            <h4 class="pubtitle">Adaptive SVM+: Learning with privileged information for domain adaptation</h4>
                                                            <div class="pubauthor">N. Sarafianos, <strong>M. Vrigkas</strong>, I.A. Kakadiaris</div>
                                                            <div class="pubcite"><span class="label label-danger">Conference Paper</span>IEEE International Conference on Computer VisionWorkshops, pp. 2637-2644, Venice, Italy, October 22-29 2017</div>
                                                        </div>
                                                        <div class="pubdetails">
                                                            <h4>Abstract</h4>
                                                            <div class="span-boxcolor">
                                                            <p align="justify">Incorporating additional knowledge in the learning process can be beneficial for several computer vision and machine learning tasks. Whether privileged information originates from a source domain that is adapted to a target domain, or as additional features available at training time only, using such privileged (i.e., auxiliary) information is of high importance as it improves the recognition performance and generalization. However, both primary and privileged information are rarely derived from the same distribution, which poses an additional challenge to the recognition task. To address these challenges, we present a novel learning paradigm that leverages privileged information in a domain adaptation setup to perform visual recognition tasks. The proposed framework, named Adaptive SVM+, combines the advantages of both the learning using privileged information (LUPI) paradigm and the domain adaptation framework, which are naturally embedded in the objective function of a regular SVM. We demonstrate the effectiveness of our approach on the publicly available Animals with Attributes and INTERACT datasets and report state-of-the-art results in both of them.
                                        										</p>
                                                            </div>
                                                            <br>
                                                            <h4>BibTex</h4>
                                                            <pre xml:space="preserve">
@inproceedings{NSarafianos_ICCVW17,
  author    = {Nikolaos Sarafianos and Michalis Vrigkas and Ioannis A. Kakadiaris},
  title     = {Adaptive SVM+: Learning with privileged information for domain adaptation},
  booktitle = {Proc. IEEE International Conference on Computer Vision Workshops},
  year      = {2017},
  month     = {October},
  pages     = {2637--2644},
  address   = {Venice, Italy}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                    </div>

                                                  <!--IEEE TAffC 2017-->
                                                  <div class="item mix jpaper 2017" data-year="2017">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=7350122&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D735012" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Journals/J5_Vrigkas_IEEE_TAFFC_2017.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2017</div>
                                                          <h4 class="pubtitle">Identifying human behaviors using synchronized audio-visual cues</h4>
                                                          <div class="pubauthor"><strong>M. Vrigkas</strong>, C. Nikou, I.A. Kakadiaris</div>
                                                          <div class="pubcite"><span class="label label-success">Journal Paper</span>IEEE Transactions on Affective Computing, vol. 8, no. 1, pp. 54-66, January-March 2017</div>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">In this paper, a human behavior recognition method using multimodal features is presented. We focus on modeling individual and social behaviors of a subject (e.g., friendly/aggressive or hugging/kissing behaviors) with a hidden conditional random field (HCRF) in a supervised framework. Each video is represented by a vector of spatio-temporal visual features (STIP, head orientation and proxemic features) along with audio features (MFCCs). We propose a feature pruning method for removing irrelevant and redundant features based on the spatio-temporal neighborhood of each feature in a video sequence. The proposed framework assumes that human movements are highly correlated with sound emissions. For this reason, canonical correlation analysis (CCA) is employed to find correlation between the audio and video features prior to fusion. The experimental results, performed in two human behavior recognition datasets including political speeches and human interactions from TV shows, attest the advantages of the proposed method compared with several baseline and alternative human behavior recognition methods.
                                                          </p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@article{MVrigkas_TAffC15,
  author  = {Michalis Vrigkas and Christophoros Nikou and Ioannis A. Kakadiaris},
  title   = {Identifying human behaviors using synchronized audio-visual cues},
  journal = {IEEE Transactions on Affective Computing},
  year    = {2017},
  volume  = {8},
  number  = {1},
  pages   = {54-66},
  doi     = {10.1109/TAFFC.2015.2507168},
  month   = {January}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                  <!--PhD 2016-->
                                                    <div class="item mix thesis 2016" data-year="2016">
                                                        <div class="pubmain">
                                                            <div class="pubassets">
                                                                <a href="https://www.didaktorika.gr/eadd/handle/10442/42814?locale=en" class="tooltips" title="External link" target="_blank">
                                                                    <i class="icon-external-link"></i>
                                                                </a>
                                                                <a href="publications/Theses/Vrigkas_PhD_Thesis_2016.pdf" class="tooltips" title="Download" target="_blank">
                                                                    <i class="icon-file-text-alt"></i>
                                                                </a>
                                                            </div>
                                                            <span id="publications-list">
                                                              <ul class"list-unstyled-left">
                                                                <li>
                                                                  <div class="publication-year">2016</div>
                                                            <h4 class="pubtitle">Human activity recognition using conditional random fields and privileged information</h4>
                                                            <div class="pubauthor"><strong>M. Vrigkas</strong></div>
                                                            <div class="pubcite"><span class="label label-info">PhD Thesis</span>Department of Computer Science and Engineering, University of Ioannina, May 2016</div>
                                                        </div>
                                                        <div class="pubdetails">
                                                            <h4>Abstract</h4>
                                                            <div class="span-boxcolor">
                                                            <p align="justify">
                                                              This thesis solves the problem of human activity recognition from video sequences. To model human activities, conditional random fields were applied using data from heterogeneous sources. Moreover, a novel classification scheme that is based on the learning using privileged information (LUPI) paradigm was also proposed, where privileged information is given as an additional input to the classification model and it is available only during training but never during testing. Experimental results demonstrated that privileged information helps to build a stronger classifier than one would not learn without it, while it significantly increases the recognition accuracy of the model.
                                                            </p>
                                                            </div>
                                                            <br>
                                                            <h4>BibTex</h4>
                                                            <pre xml:space="preserve">
@phdthesis{phdthesisMVrigkas16,
  author  = {Michalis Vrigkas},
  title   = {Human activity recognition using conditional random fields and privileged information},
  school  = {Department of Computer Science and Engineering, University of Ioannina},
  year    = {2018},
  month   = {May}
}</pre>
                                                          </li>
                                                        </ul>
                                                      </div>
                                                    </span>
                                                </div>


                                                    <!--ICIP 2016-->
                                                      <div class="item mix cpaper 2016" data-year="2016">
                                                          <div class="pubmain">
                                                              <div class="pubassets">
                                                                  <a href="https://ieeexplore.ieee.org/document/7532917/" class="tooltips" title="External link" target="_blank">
                                                                      <i class="icon-external-link"></i>
                                                                  </a>
                                                                  <a href="publications/Conferences/C7_ICIP_2016_Phoenix.pdf" class="tooltips" title="Download" target="_blank">
                                                                      <i class="icon-file-text-alt"></i>
                                                                  </a>
                                                              </div>
                                                              <span id="publications-list">
                                                                <ul class"list-unstyled-left">
                                                                  <li>
                                                                    <div class="publication-year">2016</div>
                                                              <h4 class="pubtitle">Active privileged learning of human activities from weakly labeled samples</h4>
                                                              <div class="pubauthor"><strong>M. Vrigkas</strong>, C. Nikou, I.A. Kakadiaris</div>
                                                              <div class="pubcite"><span class="label label-danger">Conference Paper</span>23<sup>rd</sup> IEEE International Conference on Image Processing, pp. 3036-3040, Phoenix, AZ, September 25-28 2016</div>
                                                          </div>
                                                          <div class="pubdetails">
                                                              <h4>Abstract</h4>
                                                              <div class="span-boxcolor">
                                                              <p align="justify">In many human activity recognition systems the size of the unlabeled training data may be significantly large due to expensive human effort required for data annotation. Moreover, the insufficient data collection process from heterogenous sources may cause dissimilarities between training and testing data. To address these limitations, a novel probabilistic approach that combines learning using privileged information (LUPI) and active learning is proposed. A pool-based privileged active learning approach is presented for semi-supervising learning of human activities from multimodal labeled and unlabeled data. Both uncertainty and distance from the decision boundary are used as a query inference strategies for selecting an unlabeled observation and query its label. Experimental results in four publicly available datasets demonstrate that the proposed method can identify with high accuracy complex human activities.
                                          										</p>
                                                              </div>
                                                              <br>
                                                              <h4>BibTex</h4>
                                                              <pre xml:space="preserve">
@inproceedings{MVrigkas_ICIP16,
  author    = {Michalis Vrigkas and Christophoros Nikou and Ioannis A. Kakadiaris},
  title	    = {Active privileged learning of human activities from weakly labeled samples},
  booktitle = {Proc. 23rd IEEE International Conference on Image Processing},
  year      = {2016},
  month     = {September},
  pages     = {3036--3040},
  address   = {Phoenix, AZ}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                <!--ICB 2016-->
                                                  <div class="item mix cpaper 2016" data-year="2016">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="https://ieeexplore.ieee.org/document/7550048/" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Conferences/C6_ICB_2016_Halmstad.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2016</div>
                                                          <h4 class="pubtitle">Exploiting privileged information for facial expression recognition<span style="margin-left:15px"></span></h4>
                                                          <div class="pubauthor"><strong>M. Vrigkas</strong>, C. Nikou, I.A. Kakadiaris</div>
                                                          <div class="pubcite"><span class="label label-danger">Conference Paper</span>9<sup>th</sup> IAPR International Conference on Biometrics, pp. 1-8, Halmstad, Sweden, June 13-16 2016</div>
                                                          <span class="label label-warning"><a href="http://icb2016.hh.se/Awards" target="_blank">Honorable Mention Paper Award</a></span>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">Most of the facial expression recognition methods consider that both training and testing data are equally distributed. As facial image sequences may contain information for heterogeneous sources, facial data may be asymmetrically distributed between training and testing, as it may be difficult to maintain the same quality and quantity of information. In this work, we present a novel classification method based on the learning using privileged information (LUPI) paradigm to address the problem of facial expression recognition. We introduce a probabilistic classification approach based on conditional random fields (CRFs) to indirectly propagate knowledge from privileged to regular feature space. Each feature space owns specific parameter settings, which are combined together through a Gaussian prior, to train the proposed t-CRF+ model and allow the different tasks to share parameters and improve classification performance. The proposed method is validated on two challenging and publicly available benchmarks on facial expression recognition and improved the state-of-the-art methods in the LUPI framework.
                                      										</p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@inproceedings{MVrigkas_ICIP16,
  author    = {Michalis Vrigkas and Christophoros Nikou and Ioannis A. Kakadiaris},
  title     = {Exploiting privileged information for facial expression recognition},
  booktitle = {Proc. 9th IAPR/IEEE International Conference on Biometrics},
  year      = {2016},
  month     = {June},
  pages     = {1--8},
  address   = {Halmstad, Sweden},
  doi       = {10.1109/ICB.2016.7550048},
  note      = {Honorable Mention Paper Award}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                  <!--FRONTIERS 2015-->
                                                  <div class="item mix jpaper 2015" data-year="2015">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="http://journal.frontiersin.org/article/10.3389/frobt.2015.00028/abstract" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Journals/J4_Vrigkas_FRONTIERS_2015.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2015</div>
                                                          <h4 class="pubtitle">A review of human activity recognition methods</h4>
                                                          <div class="pubauthor"><strong>M. Vrigkas</strong>, C. Nikou, I.A. Kakadiaris</div>
                                                          <div class="pubcite"><span class="label label-success">Journal Paper</span>Frontiers in Robotics and Artificial Intelligence, vol 2, no. 28, pp. 1-26, November 2015</div>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">Recognizing human activities from video sequences or still images is a challenging task due to problems, such as background clutter, partial occlusion, changes in scale, viewpoint, lighting, and appearance. Many applications, including video surveillance systems, human-computer interaction, and robotics for human behavior characterization, require a multiple activity recognition system. In this work, we provide a detailed review of recent and state-of-the-art research advances in the field of human activity classification. We propose a categorization of human activity methodologies and discuss their advantages and limitations. In particular, we divide human activity classification methods into two large categories according to whether they use data from different modalities or not. Then, each of these categories is further analyzed into sub-categories, which reflect how they model human activities and what type of activities they are interested in. Moreover, we provide a comprehensive analysis of the existing, publicly available human activity classification datasets and examine the requirements for an ideal human activity recognition dataset. Finally, we report the characteristics of future research directions and present some open issues on human activity recognition.
                                                          </p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@article{MVrigkas_FRONTIERS2015,
  author  = {Michalis Vrigkas and Christophoros Nikou and Ioannis A. Kakadiaris},
  title   = {A review of human activity recognition methods},
  journal = {Frontiers in Robotics and Artificieal Inteligence},
  volume  = {2},
  number  = {28},
  pages   = {1--26},
  year    = {2015},
  url     = {http://www.frontiersin.org/vision_systems_theory,_tools_and_applications/10.3389/frobt.2015.00028/abstract},
  doi     = {10.3389/frobt.2015.00028},
  issn    = {2296-9144}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                <!--IWSSIP 2015-->
                                                  <div class="item mix cpaper 2015" data-year="2015">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="https://ieeexplore.ieee.org/document/7314207/" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Conferences/C5_IWSSIP_London_2015.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2015</div>
                                                          <h4 class="pubtitle">Segmentation of cell clusters in Pap smear images using intensity variation between superpixels</h4>
                                                          <div class="pubauthor">M.E. Plissiti, <strong>M. Vrigkas</strong>, C. Nikou</div>
                                                          <div class="pubcite"><span class="label label-danger">Conference Paper</span> 22<sup>nd</sup> International Conference on Systems, Signals and Image Processing, pp. 184-187, London, UK, September 10-12 2015</div>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">The automated interpretation of Pap smear images is a challenging issue with several aspects. The accurate segmentation of the structuring elements of each cell is a crucial procedure which entails in the correct identification of pathological situations. However, the extended cell overlapping in Pap smear slides complicates the automated analysis of these cytological images. In this work, we propose an efficient algorithm for the separation of the cytoplasm area of overlapping cells. The proposed method is based on the fact that in isolated cells the pixels of the cytoplasm exhibit similar features and the cytoplasm area is homogeneous. Thus, the observation of intensity changes in extended subareas of the cytoplasm indicates the existence of overlapping cells. In the first step of the proposed method, the image is tesselated into perceptually meaningful individual regions using a superpixel algorithm. In a second step, these areas are merged into regions exhibiting the same characteristics, resulting in the identification of each cytoplasm area and the corresponding nuclei. The area of overlap is then detected using an algorithm that specifies faint changes in the intensity of the cytoplasm of each cell. The method has been evaluated on cytological images of conventional Pap smears, and the results are very promising.
                                      										</p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@inproceedings{MPlissiti_IWSSIP15,
  author    = {Marina E. Plissiti and Michalis Vrigkas and Christophoros Nikou},
  title     = {Segmentation of cell clusters in Pap smear images using intensity variation between superpixels},
  booktitle = {Proc. 22nd International Conference on Systems, Signals and Image Processing},
  year      = {2015},
  month     = {September},
  pages     = {184--187},
  address   = {London, UK}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                  <!--JEI 2014-->
                                                  <div class="item mix jpaper 2014" data-year="2014">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="http://dx.doi.org/10.1117/1.JEI.23.4.043016" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Journals/J3_Vrigkas_JEI_2014.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2014</div>
                                                          <h4 class="pubtitle">Robust maximum a posteriori image super-resolution</h4>
                                                          <div class="pubauthor"><strong>M. Vrigkas</strong>, C. Nikou, L.P. Kondi</div>
                                                          <div class="pubcite"><span class="label label-success">Journal Paper</span>Journal of Electronic Imaging, vol. 23, no. 4, pp. 043016, July 2014</div>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">A global robust M-estimation scheme for maximum a posteriori (MAP) image super-resolution which efficiently addresses the presence of outliers in the low-resolution images is proposed. In iterative MAP image super-resolution, the objective function to be minimized involves the highly resolved image, a parameter controlling the step size of the iterative algorithm, and a parameter weighing the data fidelity term with respect to the smoothness term. Apart from the robust estimation of the high-resolution image, the contribution of the proposed method is twofold: (1) the robust computation of the regularization parameters controlling the relative strength of the prior with respect to the data fidelity term and (2) the robust estimation of the optimal step size in the update of the high-resolution image. Experimental results demonstrate that integrating these estimations into a robust framework leads to significant improvement in the accuracy of the high-resolution image.
                                                          </p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@article{MVrigkas_JEI14,
  author  = {Michalis Vrigkas and Christophoros Nikou and Lisimachos P. Kondi},
  title   = {Robust maximum a posteriori image super-resolution},
  journal = {Journal of Electronic Imaging},
  volume  = {23},
  number  = {4},
  pages   = {043016},
  year    = {2014},
  isbn    = {1017-9909},
  doi     = {10.1117/1.JEI.23.4.043016},
  URL     = {http://dx.doi.org/10.1117/1.JEI.23.4.043016}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                <!--SETN 2014-->
                                                  <div class="item mix cpaper 2014" data-year="2014">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="https://link.springer.com/chapter/10.1007/978-3-319-07064-3_8" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Conferences/C4_Vrigkas_SETN_Ioannina_2014.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2014</div>
                                                          <h4 class="pubtitle">Classifying behavioral attributes using conditional random fields</h4>
                                                          <div class="pubauthor"><strong>M. Vrigkas</strong>, C. Nikou, I.A. Kakadiaris</div>
                                                          <div class="pubcite"><span class="label label-danger">Conference Paper</span>8<sup>th</sup> Hellenic Conference on Artificial Intelligence, pp. 95-104, Ioannina, Greece, May 15-17 2014</div>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">A human behavior recognition method with an application to political speech videos is presented. We focus on modeling the behavior of a subject with a conditional random field (CRF). The unary terms of the CRF employ spatiotemporal features (i.e., HOG3D, STIP and LBP). The pairwise terms are based on kinematic features such as the velocity and the acceleration of the subject. As an exact solution to the maximization of the posterior probability of the labels is generally intractable, loopy belief propagation was employed as an approximate inference method. To evaluate the performance of the model, we also introduce a novel behavior dataset, which includes low resolution video sequences depicting different people speaking in the Greek parliament. The subjects of the Parliament dataset are labeled as friendly, aggressive or neutral depending on the intensity of their political speech. The discrimination between friendly and aggressive labels is not straightforward in political speeches as the subjects perform similar movements in both cases. Experimental results show that the model can reach high accuracy in this relatively difficult dataset.
                                      										</p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@inproceedings{MVrigkas_SETN14,
  author    = {Michalis Vrigkas and Christophoros Nikou and Ioannis A. Kakadiaris},
  title     = {Classifying behavioral attributes using conditional random fields},
  booktitle = {Proc. 8th Hellenic Conference on Artificial Intelligence},
  year      = {2014},
  month     = {May},
  pages     = {95--104},
  volume    = {8445},
  series    = {Lecture Notes in Computer Science},
  address   = {Ioannina, Greece}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                  <!--CVIU 2014-->
                                                  <div class="item mix jpaper 2014" data-year="2014">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="http://dx.doi.org/10.1016/j.cviu.2013.11.007" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Journals/J2_Vrigkas_CVIU_2014.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2014</div>
                                                          <h4 class="pubtitle">Matching mixtures of curves for human action recognition</h4>
                                                          <div class="pubauthor"><strong>M. Vrigkas</strong>, V. Karavasilis, C. Nikou, I.A. Kakadiaris</div>
                                                          <div class="pubcite"><span class="label label-success">Journal Paper</span>Computer Vision and Image Understanding, vol. 119, pp. 27-40, February 2014</div>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">A learning-based framework for action representation and recognition relying on the description of an action by time series of optical flow motion features is presented. In the learning step, the motion curves representing each action are clustered using Gaussian mixture modeling (GMM). In the recognition step, the optical flow curves of a probe sequence are also clustered using a GMM, then each probe sequence is projected onto the training space and the probe curves are matched to the learned curves using a non-metric similarity function based on the longest common subsequence, which is robust to noise and provides an intuitive notion of similarity between curves. Alignment between the mean curves is performed using canonical time warping. Finally, the probe sequence is categorized to the learned action with the maximum similarity using a nearest neighbor classification scheme. We also present a variant of the method where the length of the time series is reduced by dimensionality reduction in both training and test phases, in order to smooth out the outliers, which are common in these type of sequences. Experimental results on KTH, UCF Sports and UCF YouTube action databases demonstrate the effectiveness of the proposed method.
                                                          </p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@article{MVrigkas_CVIU14,
  author  = {Michalis Vrigkas and Vasileios Karavasilis and Christophoros Nikou and Ioannis A. Kakadiaris},
  title   = {Matching mixtures of curves for human action recognition},
  journal = {Computer Vision and Image Understanding},
  volume  = {119},
  pages   = {27--40},
  year    = {2014},
  issn    = {1077--3142},
  doi     = {http://dx.doi.org/10.1016/j.cviu.2013.11.007}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                  <!--SPIC 2013-->
                                                  <div class="item mix jpaper 2013" data-year="2013">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="http://dx.doi.org/10.1016/j.image.2012.12.008" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Journals/J1_Vrigkas_SPIC_2013.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2013</div>
                                                          <h4 class="pubtitle">Accurate image registration for MAP image super-resolution</h4>
                                                          <div class="pubauthor"><strong>M. Vrigkas</strong>, C. Nikou, L.P. Kondi</div>
                                                          <div class="pubcite"><span class="label label-success">Journal Paper</span>Signal Processing: Image Communication, vol. 28, no. 5, pp. 494-508, May 2013</div>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">The accuracy of image registration plays a dominant role in image super-resolution methods and in the related literature, landmark-based registration methods have gained increasing acceptance in this framework. In this work, we take advantage of a maximum a posteriori (MAP) scheme for image super-resolution in conjunction with the maximization of mutual information to improve image registration for super-resolution imaging. Local as well as global motion in the low-resolution images is considered. The overall scheme consists of two steps. At first, the low-resolution images are registered by establishing correspondences between image features. The second step is to fine-tune the registration parameters along with the high-resolution image estimation, using the maximization of mutual information criterion. Quantitative and qualitative results are reported indicating the effectiveness of the proposed scheme, which is evaluated with different image features and MAP image super-resolution computation methods.
                                                          </p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@article{MVrigkas_SPIC13,
  author  = {Michalis Vrigkas and Christophoros Nikou and Lisimachos P. Kondi},
  title   = {Accurate image registration for \{MAP\} image super-resolution},
  journal = {Signal Processing: Image Communication},
  volume  = {28},
  number  = {5},
  pages   = {494--508},
  year    = {2013},
  issn    = {0923-5965},
  doi     = {10.1016/j.image.2012.12.008}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                <!--VISAPP 2013-->
                                                  <div class="item mix cpaper 2013" data-year="2013">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="http://www.scitepress.org/PublicationsDetail.aspx?ID=894gDQQcT0M=&t=1" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Conferences/C3_VISAPP_Barcelona_2013.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2013</div>
                                                          <h4 class="pubtitle">Action recognition by matching clustered trajectories of motion vectors</h4>
                                                          <div class="pubauthor"><strong>M. Vrigkas</strong>, V. Karavasilis, C. Nikou, I.A. Kakadiaris</div>
                                                          <div class="pubcite"><span class="label label-danger">Conference Paper</span>8<sup>th</sup> International Conference on Computer Vision Theory and Applications, pp. 112-117, Barcelona, Spain, February 21-24 2013</div>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">A framework for action representation and recognition based on the description of an action by time series of optical flow motion features is presented. In the learning step, the motion curves representing each action are clustered using Gaussian mixture modeling (GMM). In the recognition step, the optical flow curves of a probe sequence are also clustered using a GMM and the probe curves are matched to the learned curves using a non-metric similarity function based on the longest common subsequence which is robust to noise and provides an intuitive notion of similarity between trajectories. Finally, the probe sequence is categorized to the learned action with the maximum similarity using a nearest neighbor classification scheme. Experimental results on common action databases demonstrate the effectiveness of the proposed method.
                                      										</p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@inproceedings{MVrigkas_VISAPP13,
  author    = {Michalis Vrigkas and Vasileios Karavasilis and Christophoros Nikou and Ioannis Kakadiaris},
  title     = {Action recognition by matching clustered trajectories of motion vectors},
  booktitle = {Proc. 8th International Conference on Computer Vision Theory and Applications},
  year      = {2013},
  pages     = {112--117},
  address   = {Barcelona, Spain},
  month     = {February}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                <!--ICIP 2012-->
                                                  <div class="item mix cpaper 2012" data-year="2012">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="https://ieeexplore.ieee.org/document/6467337/" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Conferences/C2_IEEE_ICIP-Orlado-2012.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2012</div>
                                                          <h4 class="pubtitle">A fully robust framework for MAP image super-resolution</h4>
                                                          <div class="pubauthor"><strong>M. Vrigkas</strong>, C. Nikou, L.P. Kondi</div>
                                                          <div class="pubcite"><span class="label label-danger">Conference Paper</span>19<sup>th</sup> IEEE International Conference on Image Processing, pp. 2225-2228, Orlando, FL, September 30-October 3 2012</div>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">In this work, we propose an adaptive M-estimation scheme for robust image super-resolution. The proposed algorithm relies on a maximum <em>a posteriori</em> (MAP) framework and addresses the presence of outliers in the low resolution images. Moreover, apart from the robust estimation of the high resolution image, the contribution of the method is twofold: (i) the robust computation of the regularization parameters controlling the relative strength of the prior with respect to the data fidelity term and (ii) the robust estimation of the optimal step size in the update of the high resolution image. Experimental results demonstrate that integrating these estimations into a robust framework leads to significant improvement in the accuracy of the high resolution image.
                                      										</p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@inproceedings{MVrigkas_ICIP12,
  author    = {Michalis Vrigkas and Christophoros Nikou and Lisimachos P. Kondi},
  title     = {A fully robust framework for MAP image Super-Resolution},
  booktitle = {Proc. IEEE International Conference on Image Processing},
  year      = {2012},
  pages     = {2225--2228},
  address   = {Orlando, FL},
  month     = {September}
}</pre>
                                                            </li>
                                                          </ul>
                                                        </div>
                                                      </span>
                                                  </div>

                                                <!--ICASSP 2011-->
                                                  <div class="item mix cpaper 2011" data-year="2011">
                                                      <div class="pubmain">
                                                          <div class="pubassets">
                                                              <a href="https://ieeexplore.ieee.org/document/5946570/" class="tooltips" title="External link" target="_blank">
                                                                  <i class="icon-external-link"></i>
                                                              </a>
                                                              <a href="publications/Conferences/C1_IEEE_ICASSP-Prague-2011.pdf" class="tooltips" title="Download" target="_blank">
                                                                  <i class="icon-file-text-alt"></i>
                                                              </a>
                                                          </div>
                                                          <span id="publications-list">
                                                            <ul class"list-unstyled-left">
                                                              <li>
                                                                <div class="publication-year">2011</div>
                                                          <h4 class="pubtitle">On the improvement of image registration for high accuracy super-resolution</h4>
                                                          <div class="pubauthor"><strong>M. Vrigkas</strong>, C. Nikou, L.P. Kondi</div>
                                                          <div class="pubcite"><span class="label label-danger">Conference Paper</span>IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 981-984, Prague, Czech Republic, May 22-27 2011</div>
                                                      </div>
                                                      <div class="pubdetails">
                                                          <h4>Abstract</h4>
                                                          <div class="span-boxcolor">
                                                          <p align="justify">Accurate image registration plays a preponderant role in image super-resolution methods and in the related literature landmarkbased registration methods have gained increasing acceptance in this framework. However, their solution relies on point correspondences and on least squares estimation of the registration parameters necessitating further improvement. In this work, a maximum a posteriori scheme for image super-resolution is presented where the image registration part is accomplished in two steps. At first, the lowresolution images are registered by establishing correspondences between robust SIFT features. In the second step, the estimation of the registration parameters is fine-tuned along with the estimation of the high resolution image, in an iterative scheme, using the maximization of the mutual information criterion. Numerical results showed that the reconstructed image is consistently of higher quality than in standard MAP-based methods employing only landmarks.
                                      										</p>
                                                          </div>
                                                          <br>
                                                          <h4>BibTex</h4>
                                                          <pre xml:space="preserve">
@inproceedings{MVrigkas_ICASSP11,
  author    = {Michalis Vrigkas and Christophoros Nikou and Lisimachos P. Kondi},
  title     = {On the improvement of image registration for high accuracy super-resolution},
  booktitle = {Proc. IEEE International Conference on Acoustics, Speech and Signal Processing},
  year      = {2011},
  pages     = {981--984},
  address   = {Prague, Czech Republic},
  month     = {May}
}</pre>
                                                                </li>
                                                              </ul>
                                                            </div>
                                                          </span>
                                                      </div>

                                                      <!--Master 2010-->
                                                        <div class="item mix thesis 2010" data-year="2010">
                                                            <div class="pubmain">
                                                                <div class="pubassets">
                                                                    <a href="https://www.cse.uoi.gr/wp-content/uploads/publications/MT-2010-21.pdf" class="tooltips" title="External link" target="_blank">
                                                                        <i class="icon-external-link"></i>
                                                                    </a>
                                                                    <a href="publications/Theses/Vrigkas_MSc_Thesis_2010.pdf" class="tooltips" title="Download" target="_blank">
                                                                        <i class="icon-file-text-alt"></i>
                                                                    </a>
                                                                </div>
                                                                <span id="publications-list">
                                                                  <ul class"list-unstyled-left">
                                                                    <li>
                                                                      <div class="publication-year">2010</div>
                                                                <h4 class="pubtitle">Image super-resolution methods</h4>
                                                                <div class="pubauthor"><strong>M. Vrigkas</strong></div>
                                                                <div class="pubcite"><span class="label label-info">M.Sc. Thesis</span>Department of Computer Science, University of Ioannina, October 2010</div>
                                                            </div>
                                                            <div class="pubdetails">
                                                                <h4>Abstract</h4>
                                                                <div class="span-boxcolor">
                                                                <p align="justify">
                                                                  This thesis addresses the problem of image super-resolution. We use the term super-resolution to describe the process of obtaining a high-resolution image from a set of shifted, rotated, and degraded by noise low-resolution images. This procedure also involves the estimation of the registration parameters between the images. In the method presented here, the registration parameters between the low-resolution images are updated along with the high-resolution image in a iterative coordinate-descent optimization procedure. We describe a method for extracting distinctive invariant features from low-resolution images that can be used to perform a reliable matching between the low-resolution images in the least squares sense. In the second part of this dissertation, we propose a method of image super-resolution where the estimation of the registration parameters is fine tuned by the maximization of the mutual information registration criterion. The experimental results demonstrate that the proposed method yields sub-pixel registration accuracy and better quality of the reconstructed high-resolution image. Our method uses robust M-estimators for computing the difference between the high-resolution estimate and each low-resolution frame. The experimental results confirm the effectiveness of our method by suppressing the outliers and demonstrate the superior performance over other robust image super-resolution algorithms.
                                                                </p>
                                                                </div>
                                                                <br>
                                                                <h4>BibTex</h4>
<pre xml:space="preserve">
@phdthesis{mscthesisMVrigkas10,
author  = {Michalis Vrigkas},
title   = {Image super-resolution methods},
school  = {Department of Computer Science, University of Ioannina},
year    = {2010},
month   = {October}
}</pre>
                                                              </li>
                                                            </ul>
                                                          </div>
                                                        </span>
                                                      </div>

                                                      <!--BSc 2008-->
                                                        <div class="item mix thesis 2008" data-year="2008">
                                                            <div class="pubmain">
                                                                <div class="pubassets">
                                                                    <a href="publications/Theses/Vrigkas_BSc_Thesis_2008.pdf" class="tooltips" title="Download" target="_blank">
                                                                        <i class="icon-file-text-alt"></i>
                                                                    </a>
                                                                </div>
                                                                <span id="publications-list">
                                                                  <ul class"list-unstyled-left">
                                                                    <li>
                                                                      <div class="publication-year">2008</div>
                                                                <h4 class="pubtitle">Image inpainting by partial differential equations</h4>
                                                                <div class="pubauthor"><strong>M. Vrigkas</strong></div>
                                                                <div class="pubcite"><span class="label label-info">B.Sc. Thesis</span>Department of Computer Science, University of Ioannina, September 2008</div>
                                                            </div>
                                                            <div class="pubdetails">
                                                                <h4>Abstract</h4>
                                                                <div class="span-boxcolor">
                                                                <p align="justify">
                                                                  A technique for filling in areas with missing data in both black and white and color images is presented here. Image inpainting is the technique of modifying an image in an undetectable way. After the users select the area they want to restore, the algorithm automatically fills the area with the information that surrounds it. This technique, in contrast to previous approaches, does not require the user to determine where the information comes from. This is done automatically and it allows for the simultaneous inpainting of numerous areas, which include completely different structures and backgrounds. In addition, no restriction is required on the topology of the areas that we may inpaint. Applications of this technique include restoring old photos and damaged film, removing text such as dates, subtitles, or advertising, and removing objects such as microphones or wires. The second part of this thesis is about Poisson image processing. Using general interpolation mechanisms based on solving Poisson equations, a variety of new tools are presented for seamless image processing. The technique involves the seamless addition of both transparent and opaque objects.
                                                                </p>
                                                                </div>
                                                                <br>
                                                                <h4>BibTex</h4>
<pre xml:space="preserve">
@phdthesis{bscthesisMVrigkas08,
author  = {Michalis Vrigkas},
title   = {Image inpainting by partial differential equations},
school  = {Department of Computer Science, University of Ioannina},
year    = {2008},
month   = {October}
}</pre>
                                                              </li>
                                                            </ul>
                                                          </div>
                                                        </span>
                                                      </div>

                                                      <!-- End of pub list-->

                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- RESEARCH -->
                <div id="research" class="page">
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                              <h2 class="title">Research Summary</h2>
                                <div class="row">
                                    <div class="col-md-12" align="justify">
                                        <p>I am actively involved in learning efficient and discriminative image representations and provide solutions to challenging real-world problems. My research is focused on Computer Vision, Image and Video Processing, Machine Learning, and Augmented Reality. Special areas of research such as Biometrics, Medical Image Analysis, and Predictive Analytics for heart attack prediction have also attracted my interest. My research is focused on challenging tasks with a significant societal impact and is related to developing machine learning algorithms for real-world applications such as medical and biometric applications. </p>
										                    <p>Each of the application areas described above employs a range of computer vision tasks; more or less well-defined measurement or processing problems, which can be solved using a variety of methods. I approach these problems with methods from signal processing and applied mathematics. I have worked on several research projects and C/C++, MATLAB, and Python are the languages I prefer to use for code developing. </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="pagecontents">
                        <div class="section color-1">
                            <div class="section-container">
                                <div class="title text-center">
                                    <h3>Research Interests</h3>
                                </div>

                                <div class="row">
                                  <div class="col-md-6">
                                      <ul class="ul-boxed list-unstyled">
                                          <li>Virtual and Augmented Reality</li>
                                          <li>Computer Vision</li>
                                          <li>Image and Video Processing</li>
                                          <li>Machine Learning</li>
                                      </ul>
                                  </div>
                                  <div class="col-md-6">
                                      <ul class="ul-boxed list-unstyled">
                                          <li>Deep Learning</li>
                                          <li>Biometrics</li>
                                          <li>Medical Image Analysis</li>
                                          <li>Predictive Analytics</li>
                                      </ul>
                                  </div>
                                </div>
                            </div>
                        </div>
                    </div>
              </div>


              <!-- DOWNLOADS -->
              <div id="download" class="page">
                  <div class="pageheader">
                      <div class="headercontent">
                          <div class="section-container">
                            <h2 class="title">Downloads</h2>
                              <div class="row">
                                  <div class="col-md-12" align="justify">
                                      <p>Below you may find a list of some codes or resources I contribute to the research community. All datasets are publicly available for research purposes only. </p>
                                      <p style="color:grey;"><em><small>&copy; <strong>Copyright Notice</strong>: This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author's copyright. These works may not be reposted without the explicit permission of the copyright holder. All persons copying this information are expected to adhere to the terms and constraints invoked by each author's copyright and/or copyright holders. All statements of fact, opinion or conclusions contained herein are those of the authors and should not be construed as representing the official views or policies of the sponsors. In most cases, these works may not be reposted without the explicit permission of the copyright holders. Please contact authors for further details.</small></em></p>
                                  </div>
                              </div>
                          </div>
                      </div>
                  </div>

                  <div class="section color-1">
                    <div class="section-container">
                        <div class="title text-center">
                            <h3>Datasets</h3>
                        </div>
                    <div class="row">
                        <div class="col-md-12">
                            <ul class="ul-withdetails">

                              <li>
                                <div class="row">
                                  <div class="col-sm-6 col-md-3">
                                    <div class="image">
                                      <img alt="image" src="images/data/FaceMask.png"  class="img-responsive">
                                      <a href="images/data/FaceMask2.png" class="popup-with-move-anim">
                                      <div class="imageoverlay">
                                        <i class="icon icon-search"></i>
                                      </div>
                                      </a>
                                    </div>
                                  </div>
                                  <div class="col-sm-6 col-md-9">
                                    <div class="meta">
                                      <h3>FaceMask Dataset</h3>
                                      <p>You can download the dataset <a href="https://mvrigkas.github.io/FaceMaskDataset/" title="FaceMask Dataset">here</a>.</p>
                                    </div>
                                  </div>
                                      </div>
                                          <div class="details">
                                              <p align="justify">The FaceMask Database consists of 4,866 images of people in diffrerent environments and situations. These images were manually collected from Google Images and annotated with LabelImg tool in YOLO format. They are divided into two categories containing people wearing face masks and people not wearing face masks. The Dataset is splited into 3 folders -the training folder, the validation folder, and the test folder.
                                              </p>
                                              <p align="justify">If you use this dataset, I would be grateful if you cite with one of the following related publications:</p>
                                              <h3>Related Publications</h3>
                                              <div id="myfont-size", align="justify">
                                                    <ol type="1">
                                                      <li><strong>M. Vrigkas</strong>, E-A. Kourfalidou, M.E. Plissiti, C. Nikou, &ldquo;<strong>FaceMask: A New Image Dataset for the Automated Identification of People Wearing Masks in the Wild.</strong>,&rdquo; Sensors. 2022; 22(3):896. https://doi.org/10.3390/s22030896. [<a href="publications/Journals/J9_Vrigkas_Sensors_2022.pdf" target="_blank">pdf</a>] [<a href="https://www.mdpi.com/1424-8220/22/3/896/htm" target="_blank">External link</a>] [<a href="publications/Journals/J9_Vrigkas_Sensors_2022.bib" target="_blank">bibtex</a>]
                                                      </li>
                                                    </ol>
                                              </div>
                                          </div>
                              </li>

                            <li>
                              <div class="row">
                                <div class="col-sm-6 col-md-3">
                                  <div class="image">
                                    <img alt="image" src="images/data/parliament.jpg"  class="img-responsive">
                                    <a href="images/data/Parliament.png" class="popup-with-move-anim">
                                    <div class="imageoverlay">
                                      <i class="icon icon-search"></i>
                                    </div>
                                    </a>
                                  </div>
                                </div>
                                <div class="col-sm-6 col-md-9">
                                  <div class="meta">
                                    <h3>Parliament Dataset</h3>
                                    <p>You can download the dataset features <a href="http://www.cse.uoi.gr/~mvrigkas/ParliamentDataset/Parliament_Dataset.zip" title="Parliament Dataset">here</a> and the dataset videos <a href="https://drive.google.com/file/d/0B_YdYwW0kOLtV25pMnJjVThZVlU/view?usp=sharing" title="Parliament Dataset">here</a>.</p>
                                  </div>
                                </div>
                                    </div>
                                        <div class="details">
                                            <p align="justify">The Parliament dataset is a collection of 228 video sequences, depicting political speeches in the Greek parliament, at a resolution of 320  240 pixels at 25 fps. All behaviors were recorded for 20 different subjects. The videos were acquired with a static camera and contain uncluttered backgrounds. The length of the video sequences is 250 frames. The video sequences were manually labeled with one of three behavioral labels: friendly (90 videos), aggressive (73 videos), or neutral (65 videos). The subjects express their opinion on a specific law proposal and they adjust their body movements and voice intensity level according to whether they agree with that or not.</p>
                                            <p align="justify">The dataset was annotated by two observers of Greek origin, who watched the videos independently and recorded their labels separately. Disagreement was resolved by a third observer. The observers were asked to categorize the videos with respect to the notions of kindness and aggressiveness according to a general perception of a political speech by a citizen with a Greek mentality as follows. (i) Subjects with large and abrupt body, head and hand movements and high speech signal amplitude are to be labeled as aggressive. This corresponds to statesmen who express strongly their disagreement with the topic discussed or a previous speech given by a political opponent. (ii) Subjects with very small variations in their motion and speech signal amplitude are to be labeled as neutral. This class includes standard political speeches only expressing a point of view without any strong indication (body motion or voice tone) of agreement or disagreement with the topic discussed. (iii) Subjects with large but smooth variations in the pose of their body and hands speaking with a normal speech signal amplitudes are to be labeled as friendly.
                                            </p>
                                            <p align="justify">If you use this dataset, I would be grateful if you cite with one of the following related publications:</p>
                                            <h3>Related Publications</h3>
                                            <div id="myfont-size", align="justify">
                                                  <ol type="1">
                                                    <li><strong>M. Vrigkas</strong>, E. Kazakos, C. Nikou and I. A. Kakadiaris, &ldquo;<strong>Human activity recognition using robust adaptive privileged probabilistic learning</strong>,&rdquo; Pattern Analysis and Applications, pp. 1-18 January 2021. [<a href="publications/Journals/J8_Vrigkas_PAA_2021.pdf" target="_blank">pdf</a>] [<a href="https://link.springer.com/article/10.1007/s10044-020-00953-x" target="_blank">External link</a>] [<a href="publications/Journals/J8_Vrigkas_PAA_2021.bib" target="_blank">bibtex</a>]</li>

                                                    <li><strong>M. Vrigkas</strong>, E. Kazakos, C. Nikou and I. A. Kakadiaris, &ldquo;<strong>Inferring human activities using robust privileged probabilistic learning</strong>,&rdquo; in Proc. IEEE International Conference on Computer Vision Workshops, pp. 2658-2665, Venice, Italy, October 22-29 2017. [<a href="publications/Conferences/C9_ICCVW_2017_2_Venice.pdf" target="_blank">pdf</a>] [<a href="publications/Conferences/C9_ICCVW_2017_2_Venice.bib" target="_blank">bibtex</a>]</li>

                                                    <li><strong>M. Vrigkas</strong>, C. Nikou and I.A. Kakadiaris, &ldquo;<strong>Identifying human behaviors using synchronized audio-visual cues</strong>,&rdquo; IEEE Transactions on Affective Computing, vol. 8, no. 1, pp. 54-66, Jan.-March, 2017. [<a href="publications/Journals/J5_Vrigkas_IEEE_TAFFC_2017.pdf" target="_blank">pdf</a>] [<a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=7350122&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7350122" target="_blank">Extrernal link</a>] [<a href="publications/Journals/J5_Vrigkas_IEEE_TAFFC_2017.bib" target="_blank">bibtex</a>]</li>

                                                    <li><strong>M. Vrigkas</strong>, C. Nikou and I.A. Kakadiaris, &ldquo;<strong>Classifying behavioral attributes using conditional random fields</strong>,&rdquo; in Proc. 8th Hellenic Conference on Artificial Intelligence, Lecture Notes in Computer Science, vol. 8445, pp. 95-104, Ioannina, Greece,  May 15-17 2014. [<a href="publications/Conferences/C4_Vrigkas_SETN_Ioannina_2014.pdf" target="_blank">pdf</a>] [<a href="publications/Conferences/C4_Vrigkas_SETN_2014.bib" target="_blank">bibtex</a>]</li>
                                                  </ol>
                                            </div>
                                        </div>
                                      </li>
                              </ul>
                            </div>
                          </div>
                    </div>
                </div>

                <div class="section color-0">
                  <div class="section-container">
                      <div class="title text-center">
                          <h3>Source Code</h3>
                      </div>
                  <div class="row">
                      <div class="col-md-12">
                          <ul class="ul-withdetails">

                            <li>
                                <div class="col-sm-12 col-md-12">
                                  <div class="meta">
                                    <h4>Javascript code for downloading images and their URLs from the Web.</h4>
                                    <div class="mbr-section-btn align-center">
                                      <a class="btn btn-primary display-7" href=".\FaceMaskDataset\FACEMASK\Download_image_url.js">Download JavaScript Code</a>
                                    </div>
                                  </div>
                                </div>
                            </li>

                            </ul>
                          </div>
                        </div>
                  </div>
                </div>

            </div>

                <!-- CONTACT -->
                <div id="contact" class="page stellar">
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                <h2 class="title">Contact Me</h2>
                                <div class="row">
                                    <div class="col-md-12">
                                        <p>I would be happy to talk to you if you need my assistance in your research or you have any suggestions or comments about my work.</p>
                                    </div>
                                    <div class="col-md-7">
                                        <ul class="list-unstyled-left">
                                            <li>
                                                <span>Michalis Vrigkas</span>
                                            </li>
                                            <li>
                                                <span>University of Western Macedonia</span>
                                            </li>
                                            <li>
                                                <span>Department of Communication and Digital Media</span>
                                            </li>
                                            <li>
                                                <span>52100 Kastoria, Greece</span>
                                            </li>
                                        </ul>
                                    </div>
                                    <div class="col-md-5">
                                      <ul class="list-unstyled">
                                          <li>
                                              <strong><i class="icon-building"></i>&nbsp;&nbsp;</strong>
                                              <span>Room 102</span>
                                          </li>
                                          <li>
                                              <strong><i class="icon-phone"></i>&nbsp;&nbsp;</strong>
                                              <span>Tel: +30 246 744 0044 </span>
                                          </li>
                                          <li>
                                              <strong><i class="icon-envelope"></i>&nbsp;&nbsp;</strong>
                                              <span>email: m v r i g k a s /at\ u o w m /dot/ g r</span>
                                          </li>
                                          <li>
                                              <strong><i class="icon-globe"></i>&nbsp;&nbsp;</strong>
                                              <span>Web: <a href="https://mvrigkas.github.io">mvrigkas.github.io</a></span>
                                          </li>
                                      </ul>
                                    </div>

                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="pagecontents">
                        <div class="section contact-office" data-stellar-background-ratio="0.1">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-7">
                                          <h2 class="title">At My Office</h2>
                                          <p>You can find me at my office located at University of Western Macedonia, Fourka Area, Kastoria, Greece.</p>
                                          <div class="row">
                                              <div class="col-md-9">
                                          <ul class="ul-card">
                                             <li>
                                              <div class="dy">
                                                <span class="degree">Office 102</span><span class="year">1st floor</span>
                                              </div>
                                              <div class=".float_center">

                                                <p class="what"><strong><i class="icon-location-arrow"></i>&nbsp;&nbsp;</strong>
                                                    <span><small>Coordinates: 40.504973, 21.248093</small></span></p>
                                                <p class="where">
                                                    <a target="_blank" href="https://uowm.gr/en/" title="University of Western Macedonia">University of Western Macedonia</a>, <br>
                                                    <a target="_blank" href="https://cdm.uowm.gr/?lang=en" title="Department of Communication and Digital Media">Department of Communication and Digital Media</a>,<br>
                                                    Fourka Area, <br>
                                                    GR 52100, Kastoria,<br>
                                                    Greece.
                                                  </p>
                                              </div>
                                            </li>
                                          </ul>

                                          </div>
                                          <div class="col-md-3">
                                            <div class="col-md-1 text-center hidden-xs hidden-sm">
                                                <i class="icon-map-marker icon-huge"></i>
                                            </div>
                                          </div>
                                          </div>
                                      </div>
                                      <div class="col-md-5 text-center hidden-xs hidden-sm">
                                          <iframe align="right" src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2761.1102013950544!2d21.24528231505137!3d40.50476505820523!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x1359fcfb43059aeb%3A0x36d28b13d9b708f6!2sUniversity%20of%20Western%20Macedonia%2C%20Kastoria!5e1!3m2!1sen!2sgr!4v1582287617130!5m2!1sen!2sgr" width="375" height="275" frameborder="0" style="border:0;" allowfullscreen="" webkitallowfullscreen mozallowfullscreen oallowfullscreen msallowfullscreen></iframe>
                                     </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div id="overlay"></div>

            </div>
        </div>

        <script xml:space="preserve" language="JavaScript">hideallbibs();</script>
        <script xml:space="preserve" language="JavaScript">hideallabstracts();</script>


    </body>
</html>
